# Elasticsearch

## 01. Elasticsearch 架构原理与核心概念

### 1.1 为什么我们需要 Elasticsearch？

在 Java Web 开发中，MySQL 是我们最熟悉的各种业务数据（订单、用户、商品）的存储主力。但在面对海量数据的 **“搜索”** 需求时，MySQL 往往力不从心

- 我们通过一个具体的电商场景来推演这个痛点

#### 场景设定

假设你正在维护一个电商系统的核心数据库，其中有一张 `product`（商品）表，数据量已经增长到了 **1 亿条**。 表结构简化如下：

- `id` (主键)
- `name` (商品名称，例如：“华为 Mate 60 Pro 5G 手机”)
- `description` (商品详情描述，长文本)



#### 痛点

##### 痛点一：模糊查询导致的全表扫描

**需求**：用户在搜索框输入关键词 **“华为手机”**

- **MySQL 方案**： 通常我们会使用 SQL 的 `LIKE` 语句：

  ```sql
  SELECT * FROM product WHERE name LIKE '%华为手机%';
  ```



**问题分析**：

1. **索引失效**：在 MySQL 的 B+Tree 索引机制中，**左模糊匹配**（即 `%` 在开头的 `%xx`）会导致索引失效
2. **全表扫描**：因为无法利用索引，数据库必须把这 **1 亿条** 数据从磁盘加载到内存，逐行对比 `name` 字段是否包含“华为手机”这四个字
3. **后果**：
   - **I/O 爆炸**：磁盘 I/O 瞬间打满
   - **响应极慢**：查询耗时可能高达几十秒甚至超时
   - **服务雪崩**：高并发下，大量慢查询会直接拖垮整个数据库，导致正常下单业务也无法进行



##### 痛点二：无法理解自然语言

**需求**：用户输入关键词 **“华为5G手机”**（注意中间加了“5G”）

**MySQL 方案**：

```sql
SELECT * FROM product WHERE name LIKE '%华为5G手机%';
```

**问题分析**：

1. **机械匹配**：MySQL 的 `LIKE` 是绝对精准的字符串子串匹配
2. **漏查数据**：
   - 如果数据库里有一条商品叫 **“华为 Mate 60 Pro 5G 智能手机”**，虽然它包含“华为”、“5G”、“手机”，但因为它的语序或者中间夹杂了其他字符，`LIKE '%华为5G手机%'` 根本匹配不到这条记录
3. **分词缺失**：MySQL 不知道“华为5G手机”其实应该拆解为 `华为` + `5G` + `手机` 三个关键词来分别匹配



##### 痛点三：缺乏相关度排名

**需求**：搜索结果应该按照“匹配程度”排序，名字里出现关键词次数多的、位置靠前的应该排在前面

**MySQL 方案**： MySQL 只能按照字段（如价格、创建时间）排序，无法计算文本的 **相关度分数**。它无法告诉你哪条记录更“符合”用户的搜索意图



#### 结论

MySQL 擅长 **事务处理 (ACID)** 和 **精确查询**（如 `WHERE id = 1`），但在 **全文检索**、**模糊匹配** 和 **海量数据分析** 场景下，它是极其低效的

这也是为什么我们需要引入 **Elasticsearch** —— 它不是要取代 MySQL，而是作为 MySQL 在“搜索能力”上的 **外挂**





### 1.2 核心原理：倒排索引

Elasticsearch 之所以快，根本原因在于它存储数据的方式与传统数据库截然不同。它使用的是一种被称为 **倒排索引** 的设计



#### 1.2.1 正排索引 vs 倒排索引

要理解 Elasticsearch 为什么能支持亿级数据的毫秒级搜索，我们必须从数据存储的最底层逻辑开始

- ES 和 MySQL 最本质的区别，在于它们对“索引”的设计理念完全相反



##### 1. 正排索引 —— MySQL

这是我们最熟悉的传统数据库存储方式

- **核心逻辑**：`Document ID` $\to$ `Content`
- **结构**：以 **文档 ID** 为 Key，存储完整的文档内容（或指向内容的指针）
- **类比**：
  - 这就像你手里的 **一本书**
  - 你可以很容易地根据页码（ID=5）找到第 5 页的内容
  - 但如果你想找“Java”这个词在书中出现在哪些页，你必须 **从第一页读到最后一页**（全表扫描）



**数据结构示意**：

| Doc ID (主键) | Content (数据)              |
| ------------- | --------------------------- |
| 1             | "Java is the best language" |
| 2             | "PHP is the best language"  |
| 3             | "Java vs PHP"               |



**搜索性能瓶颈**： 当执行 `WHERE content LIKE '%Java%'` 时：

1. 数据库无法直接定位 "Java"
2. 必须遍历 ID: 1 $\to$ 2 $\to$ 3... 逐行扫描 `Content` 字段
3. **时间复杂度**：$O(N)$。随着数据量线性增长，达到亿级时，磁盘 I/O 将直接崩溃



##### 2. 倒排索引 —— ES

Elasticsearch 之所以叫 "Elastic"，是因为它灵活；之所以叫 "Search"，是因为它采用了 **倒排索引**

- **核心逻辑**：`Content (Term)` $\to$ `List<Document ID>`
- **结构**：提取内容中的 **关键词 (Term)** 作为 Key，映射到包含该词的 **文档 ID 列表**
- **类比**：
  - 这就像书本末尾的 **“关键词索引页”**
  - 你想找 "Java"，直接翻到字母 J 的索引区，上面写着：“Java: Page 1, Page 3”
  - 你不需要阅读整本书，直接定位目标



**数据结构转换示意**： ES 在写入数据时，会通过分词器将上述 Content 拆解，重组为如下结构：

| Term (关键词) | Posting List (倒排表 - 记录 ID) |
| ------------- | ------------------------------- |
| **Java**      | `[1, 3]`                        |
| **PHP**       | `[2, 3]`                        |
| **best**      | `[1, 2]`                        |
| **language**  | `[1, 2]`                        |



**搜索性能飞跃**： 当搜索 "Java" 时：

1. ES 直接在 **Term** 列查找 "Java"（通常使用 B+ Tree 或 FST 结构，速度极快）
2. 定位成功后，直接获取对应的 ID 列表 `[1, 3]`
3. **时间复杂度**：趋近于 $O(1)$。查询时间主要取决于“结果集的大小”，而不是“数据总量的大小”



##### 3. 核心差异总结

| 维度         | 正排索引 (Forward Index)            | 倒排索引 (Inverted Index)                      |
| ------------ | ----------------------------------- | ---------------------------------------------- |
| **Key**      | Primary Key (ID)                    | Term (关键词)                                  |
| **Value**    | Row Data (文档内容)                 | List of IDs (文档编号列表)                     |
| **适用场景** | 精确查询 (`WHERE id = 1`)、范围查询 | 全文检索、复杂的组合查询                       |
| **优点**     | 写入快（直接追加数据），结构简单    | **读/搜索极快**                                |
| **缺点**     | **非主键搜索极慢** (全表扫描)       | 写入慢（需要拆词、重建索引），占用更多磁盘空间 |

> **架构师视角**： 在实际架构中，我们通常采用 **“组合拳”**：
>
> - **MySQL** 负责存储原始数据（正排），保证事务和数据的最终一致性
> - **Elasticsearch** 负责构建倒排索引，处理所有复杂的搜索请求，搜到 ID 后再回 MySQL 查详情（或者直接在 ES 存储一份副本以换取速度）



#### 1.2.2 倒排索引的物理结构

在上一节中，我们理解了 `Term -> Document ID` 的逻辑映射

- 但在海量数据下（例如 10 亿条文档，产生 5000 万个不同的 Term），如果直接把这个映射表简单地存放在磁盘或内存中，会出现两个致命问题：
  1. **内存爆撑**：Term 太多，内存根本装不下
  2. **磁盘 IO 慢**：如果全存磁盘，每次搜索都要多次随机 IO，速度无法接受

Elasticsearch (基于 Lucene) 通过精妙的数据结构设计解决了这个问题



##### 1. 三级索引结构

为了平衡“查找速度”和“内存占用”，ES 设计了三层结构：**Term Index** $\to$ **Term Dictionary** $\to$ **Posting List**

| 组件                | 存储位置 | 数据结构                          | 作用                                                         |
| ------------------- | -------- | --------------------------------- | ------------------------------------------------------------ |
| **Term Index**      | **内存** | **FST (Finite State Transducer)** | **“字典的目录”**。它是 Term Dictionary 的索引，体积极小。它不存完整的 Term，只存 Term 的前缀，用于快速定位到 Term Dictionary 的某个 Block |
| **Term Dictionary** | **磁盘** | Block 结构 (排序列表)             | **“字典本体”**。存储所有的 Term 及其元数据。通过 Term Index 定位后，再从磁盘读取对应的 Block 进行二分查找 |
| **Posting List**    | **磁盘** | 压缩数组 / Roaring Bitmap         | **“倒排表”**。记录文档 ID 及其他统计信息                     |



##### 2. 核心组件详解

###### (1) Term Index 与 FST

这是 ES 所谓“内存换时间”的关键

- **痛点**：传统的 B+ Tree 虽然查询快，但对于搜索引擎来说索引量太大，无法全放内存
- **FST 魔法**：FST 是一种类似于 Trie 树（前缀树）的图形结构，但它不仅共享前缀，还 **共享后缀**
  - *效果*：它能以极低的空间成本（通常是原始文本大小的几十分之一）存储海量 Term 的前缀信息
  - *结论*：这使得 ES 可以把整个 Term Index 长期驻留在内存中，保证了查询的第一步是 **毫秒级** 的内存操作



###### (2) Posting List 不仅仅是 ID 列表

在上一节的简化模型中，我们说倒排表存的是 `[1, 2, 3]` 这样的 ID。但在实际物理文件中，它存储的信息远不止于此：

- **Doc ID**：文档编号（用于定位）
- **Term Frequency (TF)**：该词在文档中出现的次数（用于计算相关度评分 BM25）
- **Position**：该词在文档中的位置下标（用于 `match_phrase` 短语匹配）
- **Offset**：字符偏移量（用于搜索高亮显示）



###### (3) 压缩技术

ES 索引之所以占用磁盘空间大，是因为它存了太多信息。为了减少 I/O，Lucene 对 Posting List 进行了极致压缩：

- **Frame of Reference (FOR)**：
  - 针对稠密 ID 列表（如 `[1, 2, 3... 100w]`）。
  - *原理*：存储 **Delta (差值)** 而非原始值。例如 `[73, 300, 302]` 存为 `[73, 227, 2]`。差值越小，所需的 Bit 位越少，压缩率越高
- **Roaring Bitmap (咆哮位图)**：
  - 针对 Filter 缓存和稀疏数据
  - *原理*：利用位图（Bitmap）的思想，用一个 Bit 位代表一个 ID 是否存在，极其高效地进行交集、并集运算（这解释了为什么 Filter 查询快）



##### 3. 查询全流程图解

当搜索 "Java" 时，内部发生了什么？

1. **Memory**: 在 **Term Index (FST)** 中查找 "Java"
   - FST 可能会告诉你：“Java”这个词大概在 Term Dictionary 的第 3 个磁盘块（Block）里
2. **Disk I/O**: 从磁盘加载第 3 个 Block 到内存
3. **CPU**: 在这个 Block 中通过二分查找，精确定位到 "Java" 这个 Term
4. **Disk I/O**: 根据 Term 的指针，去磁盘加载对应的 **Posting List**
5. **Compute**: 获取文档 ID，利用 TF/Position 等信息计算相关度得分

> **为什么 ES 这么耗内存？** 
>
> 答：
>
> 虽然数据存在磁盘，但为了加速查询，ES 会利用 JVM Heap 以外的物理内存（Off-heap）来缓存 **Term Index** 和 **File System Cache**
>
> 因此，生产环境部署 ES 时，通常建议把 **50% 的物理内存** 留给 Lucene 用于文件缓存，而不是全部划给 JVM Heap



#### 1.2.3 Analysis 分词原理

在 ES 中，我们将“把一段文本转换为一组 Term 的过程”称为 **Analysis (分析)**。执行这个动作的组件叫 **Analyzer (分析器)**

- 无论是在写入文档（Indexing）时，还是在执行全文搜索（Searching）时，Analysis 都是必不可少的环节



##### 1. Analyzer 的流水线结构

一个标准的 Analyzer 并不是一个单一的黑盒，而是由 **三道工序** 组成的流水线：

`Character Filters` $\to$ `Tokenizer` $\to$ `Token Filters`

| 工序       | 组件名                              | 作用                                              | 例子                                                         |
| ---------- | ----------------------------------- | ------------------------------------------------- | ------------------------------------------------------------ |
| **Step 1** | **Character Filters**  (字符过滤器) | **“预处理”**。在切分之前，对原始文本进行清洗      | 去除 HTML 标签 (`<p>xx</p>` $\to$ `xx`)；将表情符号替换为文字 |
| **Step 2** | **Tokenizer**  (分词器)             | **“切分”** (核心)。按照规则把文本“切”成一个个单词 | **Standard**: 按单词切分；<br />**Whitespace**: 按空格切分；<br />**IK**: 按中文语义切分 |
| **Step 3** | **Token Filters**  (词元过滤器)     | **“精加工”**。对切出来的单词进行增、删、改        | **Lowercase**: 转小写 (`Java` $\to$ `java`)；<br />**Stopwords**: 删停用词 (删掉 `is`, `the`)；<br />**Synonym**: 加同义词 (遇到 `iphone` 加一个 `mobile`) |



##### 2. 图解分析过程

假设我们有一段脏乱的 HTML 文本： **Input**: `"<div>I LOVE Elasticsearch!</div>"`

我们看看它如何通过 **Standard Analyzer**（ES 默认分析器）的流水线：

1. **Character Filter (html_strip)**:
   - *Input*: `"<div>I LOVE Elasticsearch!</div>"`
   - *Output*: `"I LOVE Elasticsearch!"` (标签被剥离)
2. **Tokenizer (standard)**:
   - *Input*: `"I LOVE Elasticsearch!"`
   - *Output*: `[I, LOVE, Elasticsearch]` (按标点和空格切分，感叹号丢弃)
3. **Token Filter (lowercase)**:
   - *Input*: `[I, LOVE, Elasticsearch]`
   - *Output*: `[i, love, elasticsearch]` (统一转小写)

**最终产物**: 倒排索引中存储的 Terms 就是 `i`, `love`, `elasticsearch`



##### 3. 为什么搜不到

这是 ES 新手最大的痛点：**“我明明存的是这个，为什么搜不到？”**

ES 的设计原则是：**搜索的词（Query）和索引的词（Index）必须在同一个维度（Term）上匹配**

- **场景**：
  - **文档写入时**：使用了 `Standard Analyzer`
    - 原文："iPhone" $\to$ 存入索引的 Term 是 `iphone` (小写)
  - **用户搜索时**：使用了 `Term Query` (注意：Term 查询是不分词的)
    - 用户搜："iPhone" $\to$ ES 拿着 `iPhone` (大写) 去索引里找
  - **结果**：**匹配失败**。因为索引里只有 `iphone`，没有 `iPhone`
- **正确做法**：
  - 要么使用 `Match Query`（它会用同样的 Analyzer 把你的搜索词也转成小写 `iphone`）
  - 要么使用 `Term Query` 搜 `iphone` (手动小写)



##### 4. 自定义分析器

虽然 ES 自带的 Standard Analyzer 能应付英文，但它对中文非常不友好（它会把“华为手机”切成 `华`, `为`, `手`, `机`）

- 这也引出了我们下一章的核心任务：**配置 IK 中文分词器**

在生产环境中，我们经常需要自定义分析器。例如：

```js
// 一个自定义分析器的定义示例
"analyzer": {
  "my_custom_analyzer": {
    "type": "custom",
    "char_filter": ["html_strip"],    // 1. 去标签
    "tokenizer": "standard",          // 2. 标准切分
    "filter": ["lowercase", "asciifolding"] // 3. 转小写 + 也就是把 é 转成 e
  }
}
```

> **总结**： 倒排索引不是简单的字符串匹配。 **Term 是经过 Analyzer 精心加工后的产物**



### 1.3 逻辑概念与物理架构

在学习 ES 时，初学者最容易晕头转向的就是各种名词。为了快速上手，我们可以先将其与关系型数据库（MySQL）进行类比，但必须注意它们本质上的区别



#### 1. 核心数据模型 (逻辑层)

这是开发过程中每天都会接触到的概念

| Elasticsearch 概念  | 对应 MySQL 概念     | 说明与最佳实践                                               |
| ------------------- | ------------------- | ------------------------------------------------------------ |
| **Index (索引)**    | **Table (表)**      | 数据的逻辑容器。例如 `product_index`。*(注：旧版 ES 常比喻为库，但现在它就是表)* |
| **Document (文档)** | **Row (行)**        | 一条具体的 JSON 数据。例如 `{"id":1, "name":"Phone"}`。ES 是 **面向文档** 的存储系统 |
| **Field (字段)**    | **Column (列)**     | JSON 中的 Key。例如 `name`、`price`                          |
| **Mapping (映射)**  | **Schema (表结构)** | 定义字段名称及其类型（Text, Keyword, Date 等）<br />**生产铁律**：虽然 ES 支持自动推断，但 **强烈建议手动定义 Mapping**，否则后期改结构极其痛苦 |
| **Type (类型)**     | **(已废弃)**        | 重要避坑**：<br />ES 6.x 允许一索引多 Type；<br />ES 7.x 废弃 Type（统一为 `_doc`）；<br />ES 8.x **彻底移除**<br/>**结论：忘掉这个概念，不要在设计中使用它 |



#### 2. 分布式架构 (物理层)

ES 天生就是分布式的，这是它处理 PB 级数据、实现高可用的物理基础

##### (1) Node (节点)

- **定义**：一台运行 Elasticsearch 进程的服务器（或 Docker 容器）
- **标识**：每个节点都有一个名字（`node.name`）
- **角色分工**：
  - 🧠 **Master Node (大脑)**：管理集群状态（创建/删除索引、分片分配）
  - 💪 **Data Node (苦力)**：存储数据，执行 CRUD、搜索、聚合。**对 CPU、内存、IO 要求极高**



##### (2) Cluster (集群)

- 由一个或多个配置了相同 `cluster.name` 的 Node 组成
- 它们自动协同工作，对外提供统一的服务接口（你访问任意一个节点，都能拿到整个集群的数据）



##### (3) Shards (分片) —— ⭐ 核心难点

为了解决单机存储容量的上限（比如硬盘只有 1TB，但数据有 10TB），ES 将一个 Index 切分成多个部分，每一部分叫一个 **Shard**

> 举个例子：
>
> 假设你要写一套《大英百科全书》（Index），内容太多了，一本书（单机硬盘）根本装不下，而且书太厚了翻起来特别慢。怎么办？
>
> 1. **分册出版**：你把内容拆成 3 本分册：
>    - 第一册：A - H （Shard 0）
>    - 第二册：I - Q （Shard 1）
>    - 第三册：R - Z （Shard 2）
> 2. **关系**：
>    - **Index** 就是这就叫《大英百科全书》的 **书名**（逻辑概念）
>    - **Shard** 就是那一本本实实在在的 **分册**（物理实体）

| 分片类型     | 英文              | 关键特征       | 作用                                                         |
| ------------ | ----------------- | -------------- | ------------------------------------------------------------ |
| **主分片**   | **Primary Shard** | **不可变**     | 1. 数据的“本体”<br />2. **创建索引时必须确定数量，后续无法修改** <br />   *(原因：路由算法 `hash(id) % 主分片数` 依赖此数量，改了就找不到数据了)* |
| **副本分片** | **Replica Shard** | **可动态修改** | 1. **高可用 (HA)**：主分片挂了，副本自动升为主<br />2. **提升读性能**：分担搜索压力 (Scale Out)<br />3. 它是主分片的完整拷贝 |



#### 3. 架构图解 (可视化理解)

假设有一个集群（3 个节点），索引 `product_index` 配置了 **3 个主分片，1 个副本**（即每个主分片有 1 个备份）

- **总分片数**：6 个（3 主 + 3 副）
- **分布原则**：ES 会自动将这 6 个块均匀分散，且 **主副分片绝对不在同一节点**

**可能的分布情况如下：**

```
+------------------+      +------------------+      +------------------+
|      Node 1      |      |      Node 2      |      |      Node 3      |
+------------------+      +------------------+      +------------------+
| [P0] 主分片 0     |      | [R0] 副本分片 0    |      | [P1] 主分片 1     |
|                  |      |                  |      |                  |
| [R2] 副本分片 2   |      | [P2] 主分片 2     |      | [R1] 副本分片 1    |
+------------------+      +------------------+      +------------------+
```

- **高可用推演**：如果 **Node 1** 宕机（[P0] 没了）：
  - 集群发现 [P0] 丢失
  - 立即将 **Node 2** 上的 **[R0]** 提升为新的主分片
  - 集群状态短暂变黄，但数据不丢失，服务不中断



### 🚀 生产环境最佳实践

1. **分片大小控制**：
   - 单个分片的大小建议控制在 **30GB - 50GB**。
   - *太小*：导致元数据管理开销大，搜索时跨分片合并结果慢。
   - *太大*：导致节点故障后，数据恢复（Rebalance）时间极长，拖累集群。
2. **容量规划前置**：
   - 因为**主分片数无法修改**，上线前必须根据（未来 1-2 年的数据量 / 30GB）来预估分片数。





## 02. 环境搭建与 IK 分词器配置 (1/N)

### 2.0 必知必会：什么是 Kibana？

在动手安装之前，我们必须先介绍一位 Elasticsearch 的“灵魂伴侣”—— **Kibana**

#### 1. 它是干什么的？

Elasticsearch 本身只是一个 **后端服务**，它没有图形界面，只有黑乎乎的 RESTful API 接口。如果你想查数据，只能在终端里敲复杂的 `curl` 命令，既容易出错又极其痛苦

**Kibana 就是 Elasticsearch 的官方可视化操作界面**



#### 2. 通俗类比

如果把 Elasticsearch 比作 **MySQL 数据库**，那么 Kibana 就是 **Navicat**

- **没有 Kibana**：就像你在命令行里手写SQL执行
- **有了 Kibana**：你拥有了一个强大的 **Dev Tools (开发者工具)**，它支持：
  - **语法高亮**：关键词变色，一目了然
  - **自动补全**：输入 `ma` 自动提示 `match`，防止手抖敲错
  - **数据可视化**：还能把枯燥的数据画成饼图、柱状图（这是老板最喜欢的）



### 2.1 基于 Docker Compose 快速搭建

在学习阶段，我们不建议在本机直接安装庞大的 ES 安装包，那样会污染环境且难以管理。Docker 是最佳选择

#### 1. 准备工作

- 确保电脑已安装 **Docker** 和 **Docker Compose**
- 我们选用的版本是 **Elasticsearch 8.12.2** (8.x 是当前主流稳定版)



#### 2. 编写 docker-compose.yml

请在一个空文件夹下新建 `docker-compose.yml` 文件，并粘贴以下内容，注意看 `services` 下面，我们明确了 **es** 和 **kibana** 两个服务：

```yaml
version: '3.8'

services:
  # -------------------------------------------------------
  # 1. Elasticsearch 节点 (后端引擎)
  # -------------------------------------------------------
  es:
    image: elasticsearch:8.12.2
    container_name: es-node
    environment:
      - node.name=es-node
      - cluster.name=es-docker-cluster
      - discovery.type=single-node  # 开发环境运行单节点模式
      - bootstrap.memory_lock=true  # 禁止内存交换，保证性能
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m" # 🚨 关键：限制内存，防止电脑卡死
      - xpack.security.enabled=false     # 🚨 关键：关闭账号密码，降低学习门槛
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./es-data:/usr/share/elasticsearch/data # 数据挂载
      - ./es-plugins:/usr/share/elasticsearch/plugins # 插件挂载(后续装IK用)
    ports:
      - "9200:9200" # HTTP 端口 (给 Java 代码用)
    networks:
      - es-net

  # -------------------------------------------------------
  # 2. Kibana (可视化前端)
  # -------------------------------------------------------
  kibana:
    image: kibana:8.12.2
    container_name: kibana
    ports:
      - "5601:5601" # 浏览器访问端口
    environment:
      - ELASTICSEARCH_HOSTS=http://es-node:9200 # 告诉 Kibana：ES 在哪？
      - I18N_LOCALE=zh-CN # 开启中文汉化 (对新手友好)
    networks:
      - es-net
    depends_on:
      - es # 只有 ES 启动了，Kibana 才能启动

networks:
  es-net:
    driver: bridge
```



#### 3. 启动与验证

在终端进入该文件所在目录，执行：

```
docker-compose up -d
```

等待约 30-60 秒（ES 启动比较慢），进行验证：

1. **验证 ES (后端)**：浏览器访问 `http://localhost:9200`
   - 看到 JSON 返回 `"You Know, for Search"` 即成功。
2. **验证 Kibana (前端)**：浏览器访问 `http://localhost:5601`
   - 只要能打开蓝色界面，说明成功。
   - **关键动作**：点击左侧菜单栏的 **Dev Tools (扳手图标)** —— **这就是我们要写代码的地方！**



#### 4. 常见错误排查 (必看)

如果 ES 启动后马上自动退出，通常是 Linux/Windows WSL 的虚拟内存限制太小。 **解决方法**：

```bash
# 在宿主机终端执行
sysctl -w vm.max_map_count=262144
```



### 2.2 解决中文搜索痛点：IK 分词器

Elasticsearch 自带一个 **Standard Analyzer**（标准分词器），它对英文支持很好，但对中文非常“傻”

#### 1. 为什么必须装插件？(Why)

我们要知其然，知其所以然。在安装之前，先在 Kibana Dev Tools 里运行这个测试，看看原生 ES 是怎么处理中文的：

```js
# 测试原生分词器
POST /_analyze
{
  "analyzer": "standard",
  "text": "华为手机"
}
```

**原生结果**： 它会将“华为手机”拆解成 4 个独立的字：`华`、`为`、`手`、`机`

- **痛点**：当你搜“华为”时，ES 可能会给你返回包含“中华有为”或者“手办”的文档，因为它只是匹配了单字，根本不懂“华为”是一个词



#### 2. 安装 IK Analysis 插件 (Action)

**IK 分词器** 是目前 Java 社区最主流的 ES 中文分词插件

由于我们是 Docker 环境，安装步骤如下：

**Step 1: 进入容器内部** 在终端执行：

```bash
docker exec -it es-node bash
```



**Step 2: 在线安装插件** 在容器内部终端执行（注意版本必须与 ES 版本严格一致，我们是 8.12.2）：

```bash
./bin/elasticsearch-plugin install [https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.12.2/elasticsearch-analysis-ik-8.12.2.zip](https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.12.2/elasticsearch-analysis-ik-8.12.2.zip)
```

*看见 `-> Installed analysis-ik` 提示即表示成功*



**Step 3: 退出并重启容器** 执行 `exit` 退出容器，然后重启 ES 节点让插件生效：

```bash
docker restart es-node
```

*(重启需要几十秒，请耐心等待)*



#### 3. IK 的两种核心模式 (API)

安装好后，IK 提供了两个全新的分词器。这是面试和实战中最高频的考点：

1. **`ik_smart` (智能最少切分)**
   - **特点**：颗粒度粗，只切分出最常用的词，尽量不重复
   - **场景**：通常用于 **搜索框的输入** （用户搜什么，就切成什么）
2. **`ik_max_word` (最细粒度切分)**
   - **特点**：颗粒度细，会穷尽文本中所有可能的词汇组合
   - **场景**：通常用于 **构建索引**（为了让文档能被更多关键词搜到）



#### 4. 实战对比 (Code)

请在 Kibana Dev Tools 中分别运行以下两段 DSL：

**测试 A：使用 ik_smart**

```js
POST /_analyze
{
  "analyzer": "ik_smart",
  "text": "华为5G智能手机"
}
```

- **结果**：`[华为, 5G, 智能手机]`
- **评价**：干净利落，符合人类直觉



**测试 B：使用 ik_max_word**

```js
POST /_analyze
{
  "analyzer": "ik_max_word",
  "text": "华为5G智能手机"
}
```

- **结果**：`[华为, 5G, 智能手机, 智能, 手机]`
- **评价**：它把“智能手机”拆解成了“智能”和“手机”，这样用户搜“智能”也能搜到这条数据



#### 5. 扩展词库

我们已经知道，原生 ES 的分词器（Standard Analyzer）对中文支持极差，它会把“华为手机”暴力切分成“华”、“为”、“手”、“机”

- 在中文搜索场景下，**IK Analysis 插件** 是必装的标准配置



##### 1. 那我们为什么还要搞“扩展词典”？

IK 分词器虽然内置了大量中文词汇，但它无法覆盖：

1. **网络热梗**：“蓝瘦香菇”、“奥利给”、“遥遥领先”、”鸡你太美“
2. **品牌/专业术语**：“鸿蒙OS”、“显眼包”

**后果**：如果词库里没有“鸡你太美”，IK 就会把它切成 `鸡`、`你`、`太`、`美`。用户可能搜不到这条商品



##### 3. 扩展词典配置实战 (Docker 环境)

假设我们要把 **"白嫖"** 和 **"奥利给"** 加入词库

**Step 1: 定位配置目录** 在 Docker 容器中，IK 插件的配置文件通常位于： `/usr/share/elasticsearch/config/analysis-ik/`



**Step 2: 创建/修改字典文件** 你需要创建两个文件（如果不存在）：

1. **`ext.dic` (扩展词典)**：

   ```dic
   白嫖
   奥利给
   特种兵旅游
   ```

2. **`stopword.dic` (停用词典 - 屏蔽词)**：

   - *作用*：过滤掉无意义的虚词（"的", "了", "啊"）或敏感词

   ```
   的
   了
   tmd
   ```



**Step 3: 修改配置文件 `IKAnalyzer.cfg.xml`** 打开主配置文件，指向你刚才创建的文件：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "[http://java.sun.com/dtd/properties.dtd](http://java.sun.com/dtd/properties.dtd)">
<properties>
    <comment>IK Analyzer 扩展配置</comment>
    
    <!-- 1. 加载扩展字典 -->
    <entry key="ext_dict">ext.dic</entry>
    
    <!-- 2. 加载停用词字典 -->
    <entry key="ext_stopwords">stopword.dic</entry>
    
    <!-- 3. (高级) 远程词典热更新 -->
    <!-- <entry key="remote_ext_dict">http://my-server/hot_dict.txt</entry> -->
</properties>
```



**Step 4: 重启 ES** 修改本地文件配置后，**必须重启 Elasticsearch 才能生效** 

*(注：如果不希望重启，需要使用基于 HTTP 的远程词典配置，即上面注释掉的第 3 点)*



##### 4. 验证效果

在 Kibana Dev Tools 中运行：

```js
POST /_analyze
{
  "analyzer": "ik_smart",
  "text": "我要白嫖奥利给"
}
```

- **配置前**：`[我要, 白, 嫖, 奥, 利, 给]` (惨不忍睹)
- **配置后**：`[我要, 白嫖, 奥利给]` (完美识别)



## 03. 索引与文档的 CRUD 操作

### 3.1 索引管理与 Mapping 设计

在 MySQL 中，存数据前必须先执行 `CREATE TABLE` 建表。 在 Elasticsearch 中，这个过程叫做 **Create Index**，而定义表结构的语法叫做 **Mapping**

#### A. 核心铁律：严禁依赖自动 Mapping

在 Elasticsearch 中，Mapping 相当于数据库中的 Schema（表结构定义）

ES 有一个默认开启的特性叫 **Dynamic Mapping (动态映射)**：当你向一个不存在的索引写入文档，或者向已有索引写入一个新字段时，ES 会自动猜测该字段的数据类型并更新 Mapping

在开发测试环境，这个功能很方便；但在 **生产环境**，这是一个**绝对的禁区**

##### 1. 为什么它是生产环境的噩梦？

依赖 ES 自动推断类型，往往会带来两个灾难性的后果：

- **类型推断错误**

  - **场景**：第一条数据写入 `{"price": "10.5"}`
  - **ES 行为**：ES 看到引号，将其推断为 `text` 类型
  - **后果**：后续写入 `{"price": 100}` 虽然可能成功（因为 JSON 弱类型），但当你试图对 `price` 进行 **范围查询 (Range Query)** 或 **聚合统计 (Avg/Sum)** 时，会发现根本无法计算，或者结果完全错误

  

- **Mapping 爆炸**

  - **场景**：如果你有一个动态的 `Map<String, Object>` 结构存入 ES，且 Key 是不固定的（例如用户自定义属性）
  - **ES 行为**：每一个新的 Key 都会被 ES 注册为一个新的字段
  - **后果**：ES 的 Cluster State（集群状态）会急剧膨胀。当字段数超过默认限制（1000个），后续写入会直接报错；更严重的是，庞大的元数据同步会拖垮整个集群的 Master 节点



##### 2. 解决方案：Strict Mode (严格模式)

在生产环境中，我们必须手动定义 Mapping，并显式配置 **`dynamic: "strict"`**

- **`true` (默认)**：允许自动新增字段。
- **`false`**：允许写入新字段，但 **不会索引** 该字段（搜不到），只存在于 `_source` 中
- **`strict` (推荐)**：**严禁**写入 Mapping 中未定义的字段。一旦遇到未知字段，**直接抛出异常，拒绝整条写入**

> **为什么选 strict？** 只有报错，开发人员才能第一时间发现上游业务代码的异常（比如发布了脏数据），从而保护 ES 索引结构的纯净和稳定



##### 3. 最佳实践配置模板

**请求方式**：`PUT` **请求路径**：`/<索引名称>`

```js
PUT /products
{
  "mappings": {
    // 🚨 核心配置：开启严格模式
    // 任何未在 properties 中显式定义的字段，写入时都会报错！
    "dynamic": "strict",
    
    "properties": {
      // 必须把所有字段都定义在这里
      "id": { "type": "long" },
      "name": { "type": "text" }
    }
  }
}
```



##### 4. 验证测试

**测试写入未定义字段：**

```js
POST /products/_doc
{
  "id": 1,
  "name": "Huawei Phone",
  "extra_field": "这个字段没定义" 
}
```

**预期结果**： 

- ES 会返回 `400 Bad Request` 错误，提示： 

  `mapping set to strict, dynamic introduction of [extra_field] within [products] is not allowed`

- **结论**：这个报错就是对你数据的最大保护



#### B. 核心数据类型

在 Elasticsearch 中，选择正确的数据类型不仅影响搜索的准确性，还直接决定了磁盘占用和内存开销。我们将重点说说最常用、也最容易踩坑的几类

##### 1. 字符串类型：Text vs Keyword

这是 ES 新手最容易混淆的概念。请务必背下这张对比表：

| 特性         | Text (文本)                                                  | Keyword (关键字)                                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **底层处理** | **分词 (Analyzed)**。存入前会被分词器拆解                    | **不分词 (Not Analyzed)**。原样存储                          |
| **倒排索引** | 存的是拆解后的单词 (Term)。例："Apple Store" $\to$ `apple`, `store` | 存的是完整的字符串。例："Apple Store" $\to$ `Apple Store`    |
| **搜索场景** | **全文检索 (`match`)**。搜 "Apple" 能匹配到 "Apple Store"    | **精确匹配 (`term`)**。只有搜 "Apple Store" 才能匹配         |
| **高级功能** | **不支持** 聚合 (Aggs) 和 排序 (Sort)。*(强行开启需消耗大量堆内存，严禁在生产环境使用)* | **支持** 高性能的聚合和排序。*(利用 DocValues 机制，速度极快)* |
| **典型字段** | 文章正文、商品标题、描述、评论                               | 品牌(`Apple`)、状态(`active`)、手机号、枚举值                |

> **💡 最佳实践：多字段 (Multi-fields)** 如果你既想对“商品标题”进行全文搜索，又想按标题进行字母排序，怎么办？ 答：**同时拥有两种类型**
>
> ```js
> "title": {
>   "type": "text",            // 默认：用于全文搜索
>   "fields": {
>     "raw": {                 // 子字段：title.raw
>       "type": "keyword"      // 用于排序和聚合
>     }
>   }
> }
> ```



##### 2. 数值类型

ES 支持多种数值类型，原则是：**够用就好，越小越好**

| 类型               | 范围/说明                    | 推荐场景                                                     |
| ------------------ | ---------------------------- | ------------------------------------------------------------ |
| **`long`**         | 64位整数 (同 Java Long)      | ID、时间戳、大整数                                           |
| **`integer`**      | 32位整数 (同 Java Integer)   | 库存、销量、年龄                                             |
| **`short`**        | 16位整数                     | 状态码 (0~65535)                                             |
| **`byte`**         | 8位整数                      | 枚举标记 (0~127)                                             |
| **`double`**       | 64位浮点数                   | 价格、经纬度 (高精度)                                        |
| **`float`**        | 32位浮点数                   | 评分 (如 4.5)                                                |
| **`scaled_float`** | **缩放浮点数** (底层存 long) | **价格优化**<br />比如价格只精确到分，设置 `scaling_factor: 100`。存 `19.99`，底层存 `1999`。**省空间，速度快** |



##### 3. 日期类型 (Date) —— 常见的坑

ES 底层默认将时间存储为 **UTC 毫秒级时间戳 (long)**

- **痛点**：Java 里的 `2023-12-01` 和 ES 默认格式可能不匹配，导致写入报错
- **解决方案**：在 Mapping 中显式定义 `format`

```js
"created_at": {
  "type": "date",
  // 允许接收这三种格式，且能自动识别
  "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
}
```



##### 4. 布尔类型 (Boolean)

- **`boolean`**：存储 `true` 或 `false`
- **冷知识**：它也接受字符串 `"true"` / `"false"`，ES 会自动转换



##### 5. 对象类型 (Object)

ES 是面向文档的，支持 JSON 嵌套

```js
// 写入数据
{
  "manager": {
    "name": "John",
    "age": 30
  }
}
```

- **Mapping 定义**： 不需要专门定义 `object` 类型，直接定义 `properties` 嵌套即可

- **数组扁平化陷阱**： 

  - 如果你存的是对象数组：`[{"name":"John", "age":30}, {"name":"Alice", "age":20}]` 

    ES 实际上会把它“拍扁”存储为： `manager.name: ["John", "Alice"]` `manager.age: [30, 20]` 

  - **后果**：你无法精准搜索“名字是 John 且 年龄是 30”的对象（因为关联关系丢失了）

  - *(如果需要保持关联，必须使用高级的 `Nested` 类型，后续章节会讲)*



#### C. 索引创建语法详解与实战

在这一节，我们不急着写代码，而是先 **看懂** 代码

- 创建索引的 DSL（Domain Specific Language）看似复杂，其实结构非常清晰，它由 **请求行** 和 **Body** 两部分组成

##### 1. 请求行语法

在 Kibana Dev Tools 中，你会看到这样的第一行代码：

```
PUT /products
```

**语法拆解**：

- **`PUT` (动词)**：HTTP 方法。在 RESTful 风格中，`PUT` 用于 **创建** 或 **修改** 资源
- **`/products` (路径)**：这是资源的 URI
  - `/` 代表根节点
  - `products` 是你自定义的 **索引名称**（必须小写，不能包含特殊字符）

> **💡 为什么没有 URL？(URL 省略机制)** 你可能疑惑：不需要写 `http://localhost:9200` 吗？
>
> - **在 Java 代码 / Postman 中**：必须写完整 URL
> - **在 Kibana Dev Tools 中**：这是 **简写模式** 
>   - Kibana 后台已经配置好了连接 ES 的地址，它会自动帮你把 `/products` 拼接到 Base URL 后面。所以在这里，**只写路径即可**



##### 2. Body 核心骨架

创建索引的 JSON Body 主要由两大“护法”组成：**Settings** 和 **Mappings**

```js
PUT /<索引名>
{
  // --- 1. Settings (物理配置) ---
  // 决定数据“怎么存”。
  // 比如：切成几块(分片)? 备份几份(副本)?
  "settings": {
     ...
  },

  // --- 2. Mappings (逻辑定义) ---
  // 决定数据“长什么样”。
  // 比如：有哪些字段? 字段是什么类型? 用什么分词器?
  "mappings": {
     ...
  }
}
```



##### 3. Settings 语法

这里配置的是索引的 **静态属性**（部分创建后不可改）

**标准语法格式**：

```js
"settings": {
  "number_of_shards": 3,    // [不可改] 主分片数。决定了能存多少数据
  "number_of_replicas": 1,  // [可修改] 副本分片数。决定了能扛多少并发查询和容灾能力
  "refresh_interval": "1s"  // [可修改] 数据写入后多久能被搜到
}
```



##### 4. Mappings 语法

这里是定义表结构的核心区域

**标准语法格式**：

```js
"mappings": {
  // A. 全局配置
  "dynamic": "strict",      // 推荐开启严格模式，禁止乱写字段

  // B. 字段定义容器
  "properties": {
    
    // C. 单个字段定义公式
    "<字段名>": {
      "type": "<数据类型>",  // 必填。如 text, keyword, long
      "<参数>": "<参数值>"   // 选填。如 analyzer, format
    }
    
  }
}
```



##### 5. 综合实战：电商商品索引

现在，我们将上述语法知识点串联起来，编写一个完整的电商商品索引。请尝试通读这段代码，看是否能理解每一行的作用

```js
PUT /products
{
  // 1. 物理配置
  "settings": {
    "number_of_shards": 3,    // 预估数据量大，分3片
    "number_of_replicas": 1   // 一主一备，防丢失
  },

  // 2. 逻辑结构
  "mappings": {
    "dynamic": "strict",      // 严禁写入脏数据
    "properties": {
      
      // ID (数值型)
      "id": { 
        "type": "long" 
      },

      // 标题 (文本型 - 需分词)
      "title": {
        "type": "text",
        // 语法：指定特定参数
        "analyzer": "ik_max_word",    // 写入用细粒度
        "search_analyzer": "ik_smart" // 搜索用粗粒度
      },

      // 分类 (关键字 - 不分词)
      "category": {
        "type": "keyword"
      },

      // 价格 (浮点型)
      "price": {
        "type": "double"
      },
      
      // 创建时间 (日期型 - 指定格式)
      "created_at": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"
      }
    }
  }
}
```

**运行结果**： 如果执行成功，ES 会返回：

```js
{
  "acknowledged": true,       // 收到请求
  "shards_acknowledged": true, // 分片分配成功
  "index": "products"         // 索引名
}
```



#### D. 常用管理操作 (DDL)

如同 MySQL 的 `DESC`、`DROP` 和 `ALTER TABLE`，ES 也有对应的管理指令。 但由于底层倒排索引的特性，ES 的“修改”操作与关系型数据库有本质区别

##### 1. 查看索引结构 (Describe)

当你接手一个新项目，或者忘记了某个字段的类型时，用这个命令查看“表结构”

**语法**：`GET /<索引名>`

```js
GET /products
```

**返回结果解读**： 你会看到 `mappings` 下的字段定义，以及 `settings` 下的分片配置



##### 2. 删除索引 (Drop)

**⚠️ 高危操作** 这不仅仅是删除表结构，而是**物理删除**该索引下的所有数据文件。 数据一旦删除，除非有快照备份，否则 **瞬间清空且无法恢复**

**语法**：`DELETE /<索引名>`

```js
DELETE /products
```



##### 3. 修改索引 (Alter)

这是最容易踩坑的地方。请记住八字口诀：**“已有莫动，新增可行”**

**(A) 修改已存在字段：❌ 绝对禁止**

- **场景**：`price` 字段原本是 `integer`，你想改成 `double`；或者想修改 `title` 的分词器
- **ES 机制**：倒排索引是根据旧的 Mapping 定义生成的。一旦修改了定义，旧数据就变成了“孤魂野鬼”，根本无法被检索
- **结果**：ES 会直接报错，阻止你修改已存在字段的类型



**(B) 添加全新字段：✅ 允许**

- **场景**：业务迭代，需要给商品加一个 `tags`（标签）字段
- **语法**：使用 `_mapping` 接口

```js
# 语法：PUT /<索引名>/_mapping
PUT /products/_mapping
{
  "properties": {
    "tags": {
      "type": "keyword" // 新增一个 keyword 类型的字段
    }
  }
}
```

- **执行后**：
  - 新写入的文档可以包含 `tags` 字段
  - 旧文档的 `tags` 字段为空（除非你更新它们）



##### 4. 如果非要改已有字段怎么办？(Reindex)

如果你确实设计失误，必须把 `title` 的分词器从 Standard 改成 IK，唯一的办法就是 **“搬家”**

**标准流程 (Reindex)**：

1. **创建新索引**：新建一个 `products_v2`，并在里面定义正确的 Mapping（使用 IK 分词器）

2. **数据迁移**：使用 `_reindex` API 把数据从 v1 导过去

   ```js
   POST /_reindex
   {
     "source": { "index": "products" },
     "dest": { "index": "products_v2" }
   }
   ```

3. **无感切换**：修改别名（Alias），让应用层指向 `products_v2`（后续进阶章节会细讲）

> **总结**：
>
> - 查结构：`GET`
> - 删库：`DELETE`
> - 加字段：`PUT /.../_mapping`
> - 改字段：**不支持**（只能重建）



#### E. Mapping 高级参数：index 属性

在定义字段时，除了指定 `type`（类型），我们还可以通过 `index` 参数来控制 **“这个字段是否允许被搜索”**

##### 1. `index` 属性的作用

- **默认值**：`true`
- **含义**：
  - `true`：ES 会为该字段构建 **倒排索引**。你可以用 `match` 或 `term` 搜索到它
  - `false`：**不构建倒排索引**。该字段 **不能被搜索**，只能随着文档被读取出来（展示用）



##### 2. 为什么要设置为 `false`？(降本增效)

建立倒排索引是需要消耗 **磁盘空间** 和 **写入 CPU** 的

如果某个字段（比如“商品图片 URL”、“无意义的内部流水号”）永远不会被当作搜索条件，仅仅是前端页面需要展示它，那么把它设为 `false` 可以显著节省资源



##### 3. 实战示例：商品图片 URL

**场景**： 商品有一个 `img_url` 字段，存的是 CDN 图片地址。 用户永远不会在搜索框里输入 `http://.../a.jpg` 来找商品，但前端页面必须展示这张图

**Mapping 写法**：

```js
PUT /products
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "index": true    // 默认值，可以不写。允许被搜索。
      },
      
      // 🚫 关键优化：不建立倒排索引
      "img_url": {
        "type": "keyword",
        "index": false   
      }
    }
  }
}
```



##### 4. 验证效果

**步骤 A：写入数据**

```js
POST /products/_doc/1
{
  "title": "iPhone 15",
  "img_url": "[http://img.com/iphone.jpg](http://img.com/iphone.jpg)"
}
```

**步骤 B：尝试搜索 URL (会报错)**

```js
GET /products/_search
{
  "query": {
    "term": {
      "img_url": "[http://img.com/iphone.jpg](http://img.com/iphone.jpg)"
    }
  }
}
```

**结果**： ES 会直接抛出异常：`Cannot search on field [img_url] since it is not indexed.` （这就证明了并没有为它生成倒排索引）



##### 5. 辨析：`index: false` vs `_source`

很多新手搞不清“不索引”和“不存储”的区别

| 概念       | 对应配置                         | 含义                                   | 影响                                                         |
| ---------- | -------------------------------- | -------------------------------------- | ------------------------------------------------------------ |
| **不索引** | `index: false`                   | **搜不到**。但数据还在 JSON 原始文档里 | 这里的 `img_url` 不能用来搜索，但 `GET /products/1` 时能看到它 |
| **不存储** | `_source: { "excludes": [...] }` | **看不见**。数据被扔掉了，只存了索引   | 字段能被搜到（如果 index=true），但返回结果的 JSON 里没有这个字段 |

> **总结**： 如果该字段 **只看并不搜**（如图片 URL），请设置 `"index": false`



#### F. Mapping 核心参数速查手册

在阅读别人写的 Mapping 时，你可能会被各种参数绕晕。这一节我们将高频参数进行拆解，当作您的“速查字典”

##### 1. `properties` 是什么？

- **定义**：它是 **字段定义的容器**
- **类比**：
  - 如果把 Mapping 比作 SQL 的 `CREATE TABLE` 语句
  - 那么 `properties` 就是那对 **大括号 `{ ... }`**
  - 所有具体的列名（字段名）和类型定义，都必须包裹在 `properties` 里面

**嵌套结构示例**： 注意，当字段类型是 `object` 时，里面会套娃一层 `properties`

```js
"mappings": {
  "properties": {           // 第 1 层：定义根字段
    "name": { "type": "text" },
    "manager": {
      "type": "object",
      "properties": {       // 第 2 层：定义 manager 对象内部的字段
        "age": { "type": "integer" }
      }
    }
  }
}
```



##### 2. 高频参数清单 (Cheat Sheet)

除了 `type` (类型) 和 `index` (是否索引)，以下 6 个参数是您必须掌握的

| 参数名                | 作用一句话解释                             | 默认值             | 典型应用场景                                           |
| --------------------- | ------------------------------------------ | ------------------ | ------------------------------------------------------ |
| **`analyzer`**        | **写入分词器**。决定数据怎么被切分存入索引 | `standard`         | 中文搜索必配 `ik_max_word`                             |
| **`search_analyzer`** | **搜索分词器**。决定您的搜索词怎么被切分   | 默认同 `analyzer`  | 中文搜索建议配 `ik_smart` (提升精准度)                 |
| **`format`**          | **日期格式**。防止时间解析报错             | `strict_date_...`  | 解决 Java `LocalDateTime` 与 ES 格式不兼容问题         |
| **`fields`**          | **多字段**。一个字段，两种用法             | 无                 | 让 `title` 既能全文检索 (text)，又能排序聚合 (keyword) |
| **`doc_values`**      | **正排索引**。排序和聚合的基石（列式存储） | `true` (除了 text) | **性能优化**。如果不需排序/聚合，设为 `false` 可省磁盘 |
| **`copy_to`**         | **字段组合**。把值复制到另一个字段         | 无                 | 把“姓”和“名”复制到“全名”字段，方便统一搜索             |
| **`null_value`**      | **空值替身**。让 `null` 也能被搜索         | `null` (被忽略)    | 只有设了它，才能搜到“没填手机号的用户”                 |



##### 3. 实战代码

我们将上述参数融合到一个示例中，请重点关注注释。

```js
PUT /users
{
  "mappings": {
    "properties": {
      
      // 1. analyzer & search_analyzer (分词双子星)
      "name": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart",
        
        // 2. fields (多字段：既要搜，又要排)
        "fields": {
          "raw": { 
            "type": "keyword",
            "ignore_above": 256
          }
        },
        
        // 3. copy_to (自定义全搜索字段)
        "copy_to": "all_text"
      },

      // 4. doc_values (性能优化)
      "session_id": {
        "type": "keyword",
        "doc_values": false  // 🚫 关键：如果你确定不需要对 session_id 排序或聚合，关掉它能省大量空间！
      },

      // 5. format (时间格式)
      "login_time": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss||epoch_millis"
      },
      
      // 6. null_value (空值处理)
      "mobile": {
        "type": "keyword",
        "null_value": "NULL" // 如果写入 null，ES 实际存的是字符串 "NULL"，这样就能用 term 搜到了
      },

      // 7. 这是一个“垃圾桶”字段，用来汇总其他字段的值
      "all_text": {
        "type": "text",
        "analyzer": "ik_max_word"
      }
    }
  }
}
```



##### 4. 重点解读：`doc_values` 是什么？

- **问题**：
  - 倒排索引 擅长通过“词”找“文档”。但如果你要执行“按价格排序”或“计算平均分”，倒排索引就废了（因为需要遍历所有文档找价格，极其慢）
- **解决**：**Doc Values** 是一种 **列式存储（Columnar Store）** 结构，也就是 **正排索引** 的物理实现。它把文档 ID 和字段值的关系硬存了一份
- **规则**：
  - `keyword`、`long`、`date`：**默认开启**。所以它们排序很快
  - `text`：**默认关闭**。因为文本太长，存正排索引太耗空间。（这就是为什么 `text` 字段不能直接排序的原因）

> **总结**： 这一节涵盖了 Mapping 的 80% 核心参数。下次看到 `copy_to` 或 `doc_values` 不用再慌了，回来查这张表即可



### 3.2 文档的增删改查

#### A. 单文档 CRUD 语法

在 ES 中，操作文档（Document）本质上就是操作 JSON。只要你熟悉 RESTful 风格，这些语法非常直观

为了方便理解，我们将每个操作都与 SQL 进行对照



##### 1. 新增文档 (Create)

ES 提供了两种写入方式，区别在于 **“谁来生成主键 ID”**

**方式 A：自定义 ID (推荐)** 如果你手里的数据本身就有唯一主键（如 MySQL 的 `order_id`），请务必保持一致

- **语法**：`PUT /<索引>/_doc/<ID>`
- **SQL**：`INSERT INTO products (id, title...) VALUES (1, '手机'...)`

```js
PUT /products/_doc/1001
{
  "id": 1001,
  "title": "华为 Mate 60 Pro",
  "price": 6999.00,
  "created_at": "2023-09-01 12:00:00"
}
```



**方式 B：自动生成 ID** 如果你不关心 ID 是什么（比如存日志），可以让 ES 帮你生成一个随机字符串（如 `wM0q44kB...`）

- **语法**：`POST /<索引>/_doc` (注意：这里没有 ID)

```js
POST /products/_doc
{
  "title": "一条日志数据"
}
```



##### 2. 查询文档 (Read)

这是最快、性能最好的查询方式（直接基于主键哈希定位）

**基本查询**：

- **语法**：`GET /<索引>/_doc/<ID>`
- **SQL**：`SELECT * FROM products WHERE id = 1001`

```js
GET /products/_doc/1001
```

**只查是否存在 (HEAD)**： 如果你只想知道 id 1001 是否存在，不需要看具体内容（节省带宽）：

- **语法**：`HEAD /<索引>/_doc/<ID>`
- **结果**：返回 `200 OK` (存在) 或 `404 Not Found` (不存在)



##### 3. 更新文档 (Update) —— ⚠️ 高危操作

这是本节最核心的知识点。ES 的更新分为 **“全量替换”** 和 **“局部修改”**，用错会导致字段丢失

**方式 A：全量替换 (PUT) —— 慎用！**

- **语法**：`PUT /<索引>/_doc/<ID>`
- **逻辑**：ES 的底层逻辑是 **先删除旧文档，再写入新文档**
- **风险**：如果你只传了 `price` 字段，**其他原本存在的 `title`、`created_at` 字段会全部消失！**

```js
# 😱 危险操作示范
PUT /products/_doc/1001
{
  "price": 5999.00
}
# 结果：文档 1001 现在只剩 price 字段了，其他数据全丢了
```



**方式 B：局部修改 (POST _update) —— 推荐！** 这才是真正意义上的 `UPDATE`

- **语法**：`POST /<索引>/_update/<ID>`
- **结构**：必须把要改的字段包裹在 **`"doc": { ... }`** 对象里

```js
# ✅ 安全操作示范
POST /products/_update/1001
{
  "doc": {
    "price": 5999.00  // 只改价格，其他字段保持不变
  }
}
```



##### 4. 删除文档 (Delete)

ES 的删除是 **逻辑删除**。它只是把文档标记为 `.del`，磁盘空间不会立即释放，而是由后台进程在段合并（Segment Merge）时慢慢回收

- **语法**：`DELETE /<索引>/_doc/<ID>`
- **SQL**：`DELETE FROM products WHERE id = 1001`

```js
DELETE /products/_doc/1001
```

##### 💡 语法速记卡

| 动作             | HTTP 方法 | URL 格式        | Body 结构          | 说明                        |
| ---------------- | --------- | --------------- | ------------------ | --------------------------- |
| **新增/覆盖**    | `PUT`     | `/_doc/<id>`    | `{ 完整 JSON }`    | ID 存在则覆盖，不存在则新增 |
| **自动 ID 新增** | `POST`    | `/_doc`         | `{ 完整 JSON }`    | 生成随机 ID                 |
| **查询**         | `GET`     | `/_doc/<id>`    | (无)               | 按 ID 查                    |
| **局部更新**     | `POST`    | `/_update/<id>` | `{ "doc": {...} }` | **最常用**。只改指定字段    |
| **删除**         | `DELETE`  | `/_doc/<id>`    | (无)               | 逻辑删除                    |





#### B. 批量操作 (Bulk) 

**场景**：你需要往 ES 里灌入 10 万条商品数据。 **错误做法**：在 Java 代码里写一个 `for` 循环，循环 10 万次调用 `PUT /products/_doc/id`

- **后果**：每次请求都有网络开销（TCP 握手、HTTP 头解析），导致写入速度极慢，且容易把 ES 线程池打满

**正确做法**：使用 `_bulk` API，将几千个操作打包成一个 HTTP 请求发给 ES



##### 1. 特殊的格式：NDJSON

Bulk API 不使用标准的 JSON 数组格式 `[{...}, {...}]`，而是使用一种被称为 **NDJSON (Newline Delimited JSON)** 的格式

**规则**：

1. **一行一个 JSON 对象**：不能换行，不能漂亮的格式化
2. **成对出现**（部分操作）：第一行是“动作元数据”，第二行是“具体数据”
3. **严格换行**：最后一行数据后面必须也要有一个换行符 `\n`



##### 2. 语法结构详解

```js
POST /_bulk
{ "动作": { "_index": "索引名", "_id": "ID" } }  <-- 元数据行
{ "field1": "value1", ... }                    <-- 数据行 (delete操作不需要这一行)
```

**支持的动作 (Action)**：

- **`create`**：新增。如果 ID 已存在则报错（推荐，更安全）
- **`index`**：新增或覆盖。如果 ID 已存在则替换（就是 PUT 的逻辑）
- **`update`**：局部更新
- **`delete`**：删除



##### 3. 实战演练：混合批量操作

Bulk 的强大之处在于，你可以在一个请求里混合不同的操作（比如：新增 A，删除 B，修改 C）

**DSL 示例**：

```js
POST /_bulk
{ "index": { "_index": "products", "_id": "1002" } }
{ "title": "小米 14", "price": 3999 }
{ "index": { "_index": "products", "_id": "1003" } }
{ "title": "iPhone 15", "price": 5999 }
{ "update": { "_index": "products", "_id": "1001" } }
{ "doc": { "price": 5888 } }
{ "delete": { "_index": "products", "_id": "9999" } }
```

**解析**：

1. **行 1-2**：新增/覆盖 ID 为 1002 的文档
2. **行 3-4**：新增/覆盖 ID 为 1003 的文档
3. **行 5-6**：局部更新 ID 为 1001 的文档（注意 `update` 后面跟的是 `doc` 结构）
4. **行 7**：删除 ID 为 9999 的文档（注意 `delete` 只有元数据行，没有数据行）



##### 4. 生产环境最佳实践

- **单次 Bulk 的大小**：
  - **建议值**：**5MB - 15MB**（指请求体的字节大小，不是条数）
  - **条数估算**：如果每条数据 1KB，那么一次 Bulk 大概发 5000 - 10000 条
  - *原因*：太大（如 500MB）会占用大量内存，导致频繁 GC；太小则起不到节省网络开销的作用
- **错误处理机制**：
  - **重要特性**：Bulk 是 **非原子性** 的
  - 如果第 2 条报错了（比如类型不匹配），**第 1 条和第 3 条依然会执行成功**，整个请求返回 `200 OK`
  - **排查方法**：必须检查返回结果中的 `errors` 字段
    - `"errors": false` $\to$ 全部成功
    - `"errors": true` $\to$ 部分失败。此时需要遍历返回的 `items` 数组，找出具体的错误原因
- **Java 客户端**：
  - 在 Spring Data Elasticsearch 或 Java API Client 中，通常不需要手动拼接 NDJSON 字符串，客户端提供了 `BulkRequest.Builder` 来封装这些细节



## 04. DSL 高级查询语法

### O. 查询子句的分类体系

在深入学习各种具体的查询指令之前，我们需要先建立一个宏观的分类视角

- Elasticsearch 的几十种查询子句（Query Clauses），在官方定义中只分为两大类：**叶子查询** 和 **复合查询**

#### 1. 叶子查询子句

这是查询的 **最小原子单位**。 它们用于在 **特定的字段** 上查找 **特定的值**。叶子查询通常是可以单独使用的

- **特点**：直接与数据打交道，不再包含其他查询子句
- **核心成员**：
  - **全文检索类**：`match`, `multi_match`（第 A 节讲的）
  - **精确匹配类**：`term`, `terms`, `range`（第 A 节讲的）

> **形象比喻**： 如果把查询语句比作一面墙，**叶子查询就是一块块的“砖头”**



#### 2. 复合查询子句

这是查询的 **容器与胶水**。 它们用于 **包装** 其他叶子查询或复合查询，以某种逻辑（AND, OR, NOT）将它们组合起来

- **特点**：内部必须包含其他的查询子句，不能“光杆”使用
- **核心成员**：
  - **布尔查询**：`bool`（最常用，第 B 节讲的）
  - **其他**：`dis_max` (分离最大化), `constant_score` (固定分数)

> **形象比喻**： **复合查询就是“水泥”**。它负责把“砖头”（叶子查询）粘合在一起，构建成复杂的逻辑墙体



#### 3. 结构图解

当你看到一个复杂的 DSL 时，用这个视角去拆解，瞬间就清晰了：

```js
GET /products/_search
{
  "query": {
    // 【复合查询】 (bool): 我是水泥，我负责组合
    "bool": {
      "must": [
        // 【叶子查询】 (match): 我是砖头A，我负责搜名字
        { "match": { "title": "华为" } },
        
        // 【叶子查询】 (range): 我是砖头B，我负责搜价格
        { "range": { "price": { "gte": 2000 } } }
      ]
    }
  }
}
```



### P. 基础起手式：全量查询 (Match All)

在学习复杂的搜索之前，我们需要先学会怎么 **“无条件”** 地查询数据。 这通常用于：检查索引里有没有数据、全量导出数据、或者重置测试环境。

#### 1. 核心概念

- **关键词**：`match_all`
- **SQL 类比**：`SELECT * FROM table`
- **作用**：匹配索引中的 **所有** 文档



#### 2. 标准语法

注意 `match_all` 后面是一个空对象 `{}`，因为它不需要任何参数

```js
GET /products/_search
{
  "query": {
    "match_all": {} 
  }
}
```



#### 3. 两个冷知识

**知识点 A：它是“默认”的** 如果你在 DSL 中完全不写 `"query"` 部分，直接调用 `/_search`，ES 默认执行的就是 `match_all`

```js
// 写法 A：显式写
GET /products/_search
{
  "query": { "match_all": {} }
}

// 写法 B：偷懒不写 (效果完全一样)
GET /products/_search
```

**

**知识点 B：它的分数的“1.0”** 

ES 的默认排序是按 `_score` (相关度分数) 降序

- 因为 `match_all` 对所有文档一视同仁，没有谁比谁更匹配
- 所以，**所有文档的 `_score` 都是 1.0**
- 此时，文档的返回顺序通常是按照写入顺序或底层 Lucene ID 排序（类似于随机，不可强依赖）

> **实战建议**： 如果你使用 `match_all` 仅仅是为了导出数据，不关心排序，建议显式加上 `"sort": ["_doc"]`。这会让 ES 跳过评分阶段，**性能提升显著**



### A. Match (全文) vs Term (精确)

在 ES 中，90% 的查询需求都可以归类为两类。分不清这两者，是你写出 Bug 的根源

| 查询类型  | 核心逻辑     | 生活类比                                          | 对应 SQL                     |
| --------- | ------------ | ------------------------------------------------- | ---------------------------- |
| **Match** | **“搜意思”** | 百度/Google 搜索。搜 "IPhone"，能搜出 "iphone 15" | 无直接对应 (类似高级 `LIKE`) |
| **Term**  | **“对暗号”** | 查身份证号、查订单状态。差一个标点符号都不行      | `WHERE col = 'val'`          |



#### 1. Match Query (全文检索)

**关键词**：`match` 

**适用字段**：`text` 类型（如商品标题、文章内容）

**核心机制**：**先分词，再搜索**



**执行流程**： 

- 假设索引里存了一台手机，标题是 `"Huawei Mate 60"`

  - ES 存储时（默认分词）：`["huawei", "mate", "60"]` (全小写)

  - **当用户搜 `"Huawei Mate"` 时：**

    1. **Analysis (翻译/分词)**：

       - ES 看到是 `match` 查询，会先叫来 **分词器 (Analyzer)**
       - 分词器把用户的搜索词 `"Huawei Mate"` 拆解并转小写 $\to$ `["huawei", "mate"]`

       

    2. **Search (匹配)**：

       - ES 拿着拆解后的词去索引里找
       - 发现 `huawei` 能对上，`mate` 也能对上
       - **结果**：匹配成功！



**DSL 示例**：

```js
GET /products/_search
{
  "query": {
    "match": {
      "title": "Huawei Mate" // 这里的输入会被分词器处理
    }
  }
}
```



#### 2. Term Query (精确查询)

**关键词**：`term` 

**适用字段**：`keyword`、`long`、`double`、`boolean`、`date`

**核心机制**：**不分词，原样匹配**

**执行流程图解**： 假设索引里存了一条数据，分类是 `"Smart Phone"`

- ES 存储时（Keyword 类型）：`"Smart Phone"` (原封不动，保留空格和大写)

- **当用户搜 `"Smart Phone"` 时：**

  1. **No Analysis (无翻译)**：

     - ES 看到是 `term` 查询，直接把分词器踢开
     - 用户的搜索词 `"Smart Phone"` 保持原样

     

  2. **Search (匹配)**：

     - ES 拿着 `"Smart Phone"` 去索引里找
     - 发现索引里正好有一个 `"Smart Phone"`
     - **结果**：匹配成功！



**DSL 示例**：

```js
GET /products/_search
{
  "query": {
    "term": {
      "category": "Smart Phone" // 这里的输入必须和索引里的值一模一样
    }
  }
}
```



#### 3. 巨坑：对 Text 字段用 Term 查询

这是面试必问，也是生产环境最常见的“搜不到”事故

**场景复现**：

- **数据**：存入 `"title": "Huawei"` (类型是 `text`)

  - *ES 底层实际存储*：`"huawei"` (因为 Text 默认分词器会把它转成 **小写**)

    

- **用户操作**：想用 `term` 精确查找 "Huawei"

```js
GET /products/_search
{
  "query": {
    "term": {
      "title": "Huawei" // ❌ 搜不到！
    }
  }
}
```



- **为什么搜不到？(逻辑推导)**

  1. **Term 的固执**：`term` 查询是不分词的，它拿着用户输入的 `"Huawei"` (大写 H) 直接去比对
  2. **索引的现实**：倒排索引里只有 `"huawei"` (小写 h)
  3. **比对结果**：`"Huawei" == "huawei"` ? $\to$ **False**

  

- **✅ 正确做法**：

  - **方法 A (推荐)**：改用 `match` 查询
    - `match` 会把你的搜索词 "Huawei" 也转成小写 "huawei"，这样 `huawei == huawei`，就匹配上了

  - **方法 B (硬要用)**：如果你真的需要精确匹配标题，请在 Mapping 里为 title 增加 `.keyword` 子字段，然后查 `title.keyword`



#### 4. 决策树：我该用哪个？

遇到查询需求时，按以下逻辑判断：

1. **要查的字段是“长文本”吗？** (如文章、商品名)
   - $\to$ 是 $\to$ **`match`** (让 ES 帮你分词处理)
2. **要查的字段是“枚举值、ID、数值”吗？** (如状态、价格、分类)
   - $\to$ 是 $\to$ **`term`** (必须精确匹配)
3. **是复杂的组合查询吗？** (既要搜标题，又要筛选价格)
   - $\to$ 用 **`bool`** 把它们包起来（下一节讲）



### B. 多字段搜索：Multi-Match

在实际搜索业务中，用户的一个关键词往往需要在多个字段中查找。 比如搜 **"极客时间"**，既要搜 **标题**，又要搜 **课程简介**，甚至搜 **讲师名字**



#### 1. 为什么要用 Multi-Match？

在没有 `multi_match` 之前，如果我们想实现“只要标题、简介或作者里有一个包含‘极客’就算匹配”，逻辑会非常繁琐

**❌ 繁琐逻辑（笨办法）**： 你需要手动构建一个组合查询，逻辑类似于： `标题 MATCH "极客" OR 简介 MATCH "极客" OR 作者 MATCH "极客"`

这不仅写起来麻烦，而且在计算相关度分数时，很难控制每个字段的权重

**✅ Multi-Match 写法**： 它是对上述逻辑的完美封装，语法极其简洁

```js
GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "极客",                    // 1. 搜什么？
      "fields": ["title", "description"]  // 2. 搜哪里？(数组)
    }
  }
}
```



#### 2. 核心技巧：权重提升

**场景**： 用户搜 "Spring"，可能会搜出两本书：

- 书 A：**标题** 是《Spring 实战》
- 书 B：**简介** 里提到了 "Spring"

**需求**： 显然，书 A 的相关度应该更高。我们需要**提升“标题”字段的权重**

**语法**： 在字段名后面加上 **`^N`**（N 是倍数）

```js
GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "Spring",
      "fields": [
        "title^3",       // 🚀 重点：标题匹配得分 x 3
        "description"    // 简介匹配得分 x 1 (默认)
      ]
    }
  }
}
```

**结果**： 如果 "Spring" 出现在 title 中，这条文档的分数会飙升，排名直接置顶



#### 3. 进阶：Tie Breaker (决胜局)

- **默认行为 (`best_fields`)**： 

  - 如果一个词同时出现在 `title` 和 `description` 中，ES 默认 **只取分数最高的那一个字段** 作为该文档的最终得分 

    *(比如 title 得分 10，desc 得分 5，最终文档得分就是 10)*

- **问题**： 有时我们希望：“两个字段都匹配”的文档，应该比“只有一个字段匹配”的文档分更高

- **解决**：使用 `tie_breaker` 参数

```js
{
  "multi_match": {
    "query": "Spring",
    "fields": ["title", "description"],
    "type": "best_fields", // 默认策略
    "tie_breaker": 0.3     // 🚀 加上 30% 的“备胎字段”分数
  }
}
```

- **计算公式**：`最终得分 = 最高分字段 + (其他匹配字段 * 0.3)`



### C. 组合查询详解：Bool Query

单一的 `match` 或 `term` 只能解决简单问题

- 真实业务往往是复杂的： *“我要找【华为】的手机，价格【不能超过 5000】，如果有【5G】功能最好，而且【不能是二手】的”*

这时候，就需要 **`bool` 查询** 出场了。它是将多个叶子查询组合在一起的容器



#### 1. Bool 查询的四大护法

`请死记硬背这张表，它是写复杂查询的基础

| 子句 (Key)     | 逻辑含义        | SQL 类比 | 是否算分 (_score) | 是否缓存 | 核心作用                                                     |
| -------------- | --------------- | -------- | ----------------- | -------- | ------------------------------------------------------------ |
| **`must`**     | **必须 匹配**   | `AND`    | ✅ **是**          | ❌ 否     | **核心搜索**。决定文档是否匹配，并计算相关度                 |
| **`filter`**   | **必须 匹配**   | `AND`    | ❌ **否**          | ✅ **是** | **硬性筛选**。只看是否匹配 (Yes/No)，性能极高，结果会被缓存  |
| **`should`**   | **可选 匹配**   | `OR`     | ✅ **是**          | ❌ 否     | **加分项**。匹配了得分变高，不匹配也不会被剔除（除非只有 should） |
| **`must_not`** | **必须不 匹配** | `NOT`    | ❌ **否**          | ✅ **是** | **排除项**。黑名单过滤                                       |



#### 2. 性能:Query vs Filter

这是 ES 调优的第一法则：**能用 Filter 就别用 Must！**

- **Query Context (查询上下文)**：包含 `must` 和 `should`

  - **ES 思考的问题**：*“这个文档匹配得 **有多好**？”*
  - **代价**：需要计算浮点数相关度分数 (`_score`)，无法利用缓存

  

- **Filter Context (过滤上下文)**：包含 `filter` 和 `must_not`

  - **ES 思考的问题**：*“这个文档 **匹配吗**？”* (Yes/No)
  - **优势**：不需要算分，结果会被 ES 自动缓存（BitSet 机制），速度极快

> **🚀 最佳实践**：
>
> - **文本搜索**（如 `title: "华为"`）：放 `must`
> - **结构化筛选**（如 `price > 2000`, `status = 1`, `brand = "Apple"`）：**统统放 `filter`**



#### 3. 标准语法结构 (Syntax)

- 请注意观察 `[]` (数组) 的使用：同一个逻辑下如果有多个条件，必须用数组包裹

**需求**：搜索“华为手机”，价格高于 2000，排除二手货，如果是 5G 的排在前面

```js
GET /products/_search
{
  "query": {
    "bool": {
      // 1. must: 核心搜索 (算分)
      "must": [
        { "match": { "title": "华为手机" } }
      ],
      
      // 2. filter: 硬性筛选 (不算分，缓存，快！)
      "filter": [
        { "range": { "price": { "gte": 2000 } } },
        { "term":  { "status": 1 } }
      ],
      
      // 3. must_not: 排除干扰 (不算分，缓存)
      "must_not": [
        { "term": { "tags": "二手" } }
      ],
      
      // 4. should: 锦上添花 (算分)
      "should": [
        { "match": { "description": "5G" } }
      ]
    }
  }
}
```





#### 4. 深入理解 Should (加分 vs 必须)

`should` 的行为比较特殊，它会根据当前 `bool` 查询中是否有其他子句而变化

##### 场景 A：只有 Should (OR 逻辑)

如果 `bool` 查询中 **没有** `must` 也没有 `filter`，只有 `should`

- **逻辑**：**至少满足 1 个** `should` 条件
- **SQL 类比**：`WHERE A OR B`

```js
// 搜 "Apple" 或者 "Huawei"
"bool": {
  "should": [
    { "term": { "brand": "Apple" } },
    { "term": { "brand": "Huawei" } }
  ]
}
```



##### 场景 B：Should 混搭 Must/Filter (加分逻辑)

如果 `bool` 查询中 **已经有** `must` 或 `filter` 了

- **逻辑**：`should` 变成了 **“加分项” (Bonus)**
  - 即使 `should` 里的条件一个都不满足，文档只要满足 `must/filter` 依然会返回
  - 如果满足了 `should`，文档的 `_score` 会更高，排名更靠前
- **控制**：如果你希望在混搭时，`should` 也是必须满足至少一个，需要加上参数： `"minimum_should_match": 1`



#### 5. 复杂嵌套

`bool` 查询本身也是一个 Query，所以它可以被套在另一个 `bool` 里面。 这用于实现类似 `(A OR B) AND C` 的逻辑

**需求**：查找品牌是 (Apple 或 Huawei)，且价格大于 5000 的商品。

```js
GET /products/_search
{
  "query": {
    "bool": {
      "filter": [
        // 条件 C: 价格 > 5000
        { "range": { "price": { "gt": 5000 } } },
        
        // 嵌套逻辑: (A OR B)
        {
          "bool": {
            "should": [
              { "term": { "brand": "Apple" } },  // A
              { "term": { "brand": "Huawei" } }  // B
            ],
            // 显式声明：至少满足 1 个 should，否则就变成了单纯的加分项
            "minimum_should_match": 1 
          }
        }
      ]
    }
  }
}
```



### D. 排序与分页

在解决了“怎么查”的问题后，我们还需要控制结果“怎么展示”：谁排前面？一次看多少条？

#### 1. 排序 (Sort)

默认情况下，ES 按 **相关度分数 (`_score`)** 降序排列。 如果你想按价格、时间或销量排序，就需要使用 `sort` 字段

**基础语法**：

```js
GET /products/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "price": { "order": "desc" } },       // 第一排序键：价格降序
    { "created_at": { "order": "asc" } }    // 第二排序键：时间升序
  ]
}
```

**⚠️ 经典报错：对 Text 字段排序**

- **场景**：你尝试对 `title` (text 类型) 进行排序

- **报错**：`Fielddata is disabled on text fields...`

- **原因**：`text` 字段被分词成了碎块，ES 不知道该用 "Huawei" 排，还是用 "Phone" 排

- **解决**：必须使用 **`keyword`** 子字段

  ```js
  "sort": [
    { "title.keyword": { "order": "asc" } } // ✅ 正确做法
  ]
  ```



#### 2. 基础分页 (From + Size)

ES 的分页语法逻辑与 MySQL (`LIMIT offset, size`) 非常相似

- **`from`**：跳过多少条（默认 0）
- **`size`**：返回多少条（默认 10）

**语法示例**：

```js
GET /products/_search
{
  "query": { "match_all": {} },
  "from": 0,    // 第 1 页 (0 * 10)
  "size": 10
}
```



#### 3. 生产级灾难：深度分页

**场景**：用户想看第 1000 页的数据（每页 10 条）。 计算：`from = 9990`, `size = 10`。 DSL 没问题，ES 也能返回

**场景升级**：用户想看第 5000 页。 `from = 49990`, `size = 10`

- **💥 报错**：`Result window is too large, from + size must be less than or equal to: [10000]`



**核心原理：为什么 ES 禁止深分页？** 

- ES 是分布式的。假设数据分散在 3 个分片（Shard A, B, C）上。 当你查 `from=9990, size=10` 时：
  1. **各分片工作**：Shard A、B、C 必须各自把它们认为的 **Top 10000** 条数据全部找出来，排序，然后发给协调节点（Coordinating Node）
  2. **协调节点工作**：它收到了 `3 * 10000 = 30000` 条数据。它必须在内存中对这 3 万条数据**再次排序**，抛弃前 9990 条，只取最后 10 条返回给用户

- **结论**：页码越深，协调节点的内存消耗和排序压力呈指数级增长，极易导致 OOM（内存溢出）。因此，ES 默认限制 `from + size <= 10000`



#### 4. 解决方案：如何查询 10000 条以后的数据？

如果业务真的需要导出全量数据，或者手机端无限滚动（Infinite Scroll），该怎么办？

**方案 A：Search After (推荐用于手机端/无限加载)**

- **原理**：基于上一页最后一条数据的“排序值”来查找下一页。类似于“接着读”
- **优点**：无内存压力，性能极高
- **缺点**：不支持随机跳转（不能直接跳到第 50 页，必须一页页翻）



**DSL 示例**：

```js
// 第一页
GET /products/_search
{
  "size": 10,
  "sort": [{ "price": "desc" }, { "_id": "asc" }] // 必须有一个全局唯一的字段辅助排序(如ID)
}
// 结果返回最后一条的 sort 值：[99.0, "1005"]

// 第二页
GET /products/_search
{
  "size": 10,
  "sort": [{ "price": "desc" }, { "_id": "asc" }],
  "search_after": [99.0, "1005"] // 把上一页最后一条的 sort 值填在这里
}
```



**方案 B：Scroll API (仅用于数据导出)**

- **原理**：生成一个快照（Snapshot）
- **场景**：全量数据迁移、备份
- **注意**：Scroll 会维护上下文，占用资源，**严禁用于实时用户搜索**



**方案 C：业务限制 (最常见)**

- 百度、谷歌都只允许看前 100 页
- **直接告诉产品经理**：超出 10000 条的数据不许翻页，请用户缩小搜索范围。这是最治本的方案



### E. 搜索体验优化：高亮显示

当用户在淘宝搜索“华为”时，结果列表中的“华为”两个字通常会变成红色。这就是 **高亮显示**

- 它不是前端单纯的字符串替换，而是 ES 基于倒排索引，精准定位到词条位置后动态生成的



#### 1. 核心语法骨架

高亮配置 `highlight` 是与 `query` 同级的

**需求**：搜索“华为”，并将结果中的“华为”二字标红（包裹 `<span style='color:red'>` 标签）

```js
GET /products/_search
{
  "query": {
    "match": {
      "title": "华为"
    }
  },
  
  // 🚀 核心配置区域
  "highlight": {
    "pre_tags": ["<span style='color:red'>"],   // 前缀标签 (默认是 <em>)
    "post_tags": ["</span>"],                    // 后缀标签 (默认是 </em>)
    "fields": {
      "title": {}                                // 指定要高亮的字段
    }
  }
}
```



#### 2. 返回结果解析

这是新手最容易懵的地方：**“我配置了高亮，为什么返回的 `_source` 里的 title 还是黑色的？”**

**ES 的返回结构**： ES **绝对不会** 修改原始文档 `_source`。它会把处理好的高亮片段放在一个独立的 **`highlight`** 对象中

```js
{
  "hits": [
    {
      "_index": "products",
      "_id": "1001",
      "_score": 3.5,
      
      // 1. 原始数据 (完全没变！)
      "_source": {
        "title": "华为 Mate 60 Pro",
        "price": 6999
      },
      
      // 2. 高亮片段 (东西在这里！)
      "highlight": {
        "title": [
          "<span style='color:red'>华为</span> Mate 60 Pro"
        ]
      }
    }
  ]
}
```

> **开发实战**： 在 Java 代码中，你拿到结果后，必须做一个 **“替换操作”**：
>
> 1. 取出 `highlight.title` 中的内容
> 2. 用它覆盖 `_source.title` 的内容
> 3. 然后再返回给前端



#### 3. 进阶参数：require_field_match

- **场景**： 你用 `match` 搜的是 `content` (内容)，但你想在 `title` (标题) 上做高亮
- **默认行为**： ES 默认只高亮 **查询中涉及的字段**。如果你的查询条件没查 title，即便配置了高亮 title，ES 也会忽略
- **解决**： 设置 `"require_field_match": false`

```js
"highlight": {
  "fields": {
    "title": { "require_field_match": false }
  }
}
```



#### 4. 性能隐患

高亮是一个非常消耗 CPU 的操作，因为它需要重新分析文本并定位词条偏移量

- **限制**：ES 默认限制高亮字段的最大长度（`fragment_size`），超过长度的文本会被截断
- **建议**：只对短文本（如标题、简介）做高亮，不要对几十万字的文章正文做全量高亮



## 05. Aggregations 聚合分析

### 5.1 聚合分析基础：思维模型与语法骨架

Elasticsearch 的聚合（Aggregations，简称 `aggs`）功能，相当于 SQL 中的 `GROUP BY` 和统计函数（`AVG`, `SUM`, `COUNT`）



#### A. 聚合核心理论与语法骨架

Elasticsearch 的聚合（Aggregations，简称 `aggs`）是数据分析的核武器。它不再关注“哪条文档匹配”，而是关注“这些文档的统计特征是什么”

##### 1. 核心思维模型：Bucket vs Metric

聚合的世界里只有两类角色。搞清它们的分工，是构建一切复杂报表的前提

| 角色     | 英文       | 对应 SQL              | 职责                                                         | 形象比喻                                             |
| -------- | ---------- | --------------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
| **分桶** | **Bucket** | `GROUP BY`            | **“分类”**。将文档按条件（品牌、价格区间、时间）归类到不同的“桶”里 | **理货员**：把一堆散乱的衣服，按“颜色”扔进不同的篮子 |
| **指标** | **Metric** | `COUNT`, `AVG`, `SUM` | **“计算”**。在分好的“桶”里，计算统计数值                     | **收银员**：计算每个篮子里衣服的总价、平均价         |

> **逻辑关系**：先分桶（Bucket），再计算（Metric）。也可以不分桶，直接对所有数据计算（Metric）



##### 2. 万能语法骨架

聚合的 DSL 嵌套层级较深，初学者容易迷失在括号里。请死记这个 **“三层套娃”** 结构：

```js
GET /products/_search
{
  // 🚀 关键点 1：只看统计，不看列表
  // 必须设为 0！否则 ES 会把成千上万条原始数据也返回给你，拖慢网速。
  "size": 0,
  
  // 🚀 关键点 2：先圈定范围
  // 聚合是作用在 Query 结果之上的。这里没写 query，就是针对全表聚合。
  "query": { "match_all": {} },
  
  "aggs": {
    // --- 第一层：给聚合起个名 (自定义) ---
    "my_aggregation_name": {
      
      // --- 第二层：选策略 (Terms? Range? Avg?) ---
      "<聚合类型>": {
        "field": "<目标字段>"
        // 其他参数，如 interval, size 等
      },
      
      // --- 第三层：嵌套 (可选) ---
      // 在这个桶里，再进行分桶或计算
      "aggs": { ... }
    }
  }
}
```



##### 3. 执行流水线

理解执行顺序，对性能调优至关重要

**流程图**： `原始数据 (1亿条)` $\xrightarrow{\text{Query/Filter}}$ `命中数据 (10万条)` $\xrightarrow{\text{Aggregations}}$ `统计结果 (1KB JSON)`

- **误区**：很多人以为聚合总是扫描全表
- **真相**：聚合只处理 **Query 筛选后** 的文档
- **调优口诀**：**"Filter First, Aggs Later"**。想让报表跑得快，先用 `query.bool.filter` 把无关数据（如已下架商品、去年的数据）剔除掉



#### B. 聚合基础实战：Metric 与 Bucket

掌握了语法骨架后，我们直接上手两个最基础、最高频的聚合操作

##### 1. Metric 聚合实战：数值统计

**业务场景**： 电商运营后台需要一个“价格仪表盘”，展示当前搜索结果中商品的 **最高价**、**最低价**、**平均价** 和 **总销售额**

**传统做法**： 查出所有数据，在 Java 代码里遍历计算。$\to$ **性能极差，内存溢出**

**ES 做法 (stats 聚合)**： 使用 `stats` 聚合，一次请求获取所有基础统计指标

```js
GET /products/_search
{
  "size": 0,             // 1. 不返回原始文档，只看结果
  "query": {             // 2. 限定范围：只统计“手机”类目
    "term": { "category": "手机" }
  },
  
  "aggs": {
    "price_dashboard": { // 3. 自定义聚合名称
      "stats": {         // 4. 聚合类型：stats (统计全家桶)
        "field": "price" // 5. 目标字段
      }
    }
  }
}
```

**返回结果 (Response)**： ES 极其高效地返回了计算结果：

```js
{
  ...
  "aggregations": {
    "price_dashboard": {
      "count": 120,      // 样本数量
      "min": 1999.0,     // 最低价
      "max": 8999.0,     // 最高价
      "avg": 4500.0,     // 平均价
      "sum": 540000.0    // 总和
    }
  }
}
```

> **扩展**：如果只需要某一个特定指标，可以直接使用 `min`, `max`, `avg`, `sum`, `cardinality` (去重计数) 等类型替换 `stats`



##### 2. Bucket 聚合实战：按词条分组

**业务场景**： 想统计“销量 Top 10 的品牌”或者“各个分类下的商品数量”

**ES 做法 (terms 聚合)**： 类似于 SQL 的 `GROUP BY brand_name LIMIT 10`

```js
GET /products/_search
{
  "size": 0,
  "aggs": {
    "top_brands": {       // 1. 自定义聚合名称
      "terms": {          // 2. 聚合类型：terms (按词分桶)
        "field": "brand", // 3. 目标字段 (必须是 keyword 类型)
        "size": 10,       // 4. 限制返回桶的数量 (Top 10)
        "order": {        // 5. (可选) 排序规则，默认按 doc_count 降序
          "_count": "desc" 
        }
      }
    }
  }
}
```

**返回结果 (Response)**： ES 返回一个 `buckets` 数组，清晰列出每个品牌的统计数

```js
{
  ...
  "aggregations": {
    "top_brands": {
      "doc_count_error_upper_bound": 0, // 误差上界 (分布式统计特有)
      "sum_other_doc_count": 50,        // 未展示的其他品牌总数
      "buckets": [
        {
          "key": "Apple",    // 桶名 (品牌)
          "doc_count": 80    // 文档数 (商品数)
        },
        {
          "key": "Huawei",
          "doc_count": 65
        }
        // ... 共 10 个
      ]
    }
  }
}
```



##### 3. 💣 核心避坑指南

在做 Terms 聚合时，新手 100% 会遇到以下两个问题：

**坑一：对 Text 字段聚合报错**

- **报错信息**：`Fielddata is disabled on text fields...`
- **原因**：`text` 字段是为了全文检索设计的（倒排索引），加载到内存中做聚合极其消耗资源，默认被禁用
- **解决**：
  1. **推荐**：使用 `.keyword` 子字段（如 `brand.keyword`）
  2. **不推荐**：强行开启 `fielddata: true`（极易导致 OOM，生产环境慎用）



**坑二：数据不准**

- **现象**：你查 Top 5，结果把你认为排第 5 的漏掉了
- **原因**：ES 是分布式的。如果数据分散在 3 个分片上，协调节点是把“每个分片的 Top 5”拿回来汇总，而不是“全量数据的 Top 5”。这会导致长尾数据丢失
- **解决**：
  1. 增大 `shard_size` 参数（让分片多交点数据）
  2. 增加 `size` 的返回值



### 5.2 Bucket 聚合详解：Terms 与 Histogram

Bucket 聚合的作用是 **将文档“归类”到不同的桶中**。 如果说 Metric 是算术（加减乘除），那 Bucket 就是分类学

#### 1. Terms Aggregation (按词条分桶)

这是最常用的分桶方式，对应 SQL 的 `GROUP BY field`。 它会提取字段中的唯一值（Unique Value），并统计每个值的文档数量

- **场景**：统计每个品牌（Brand）下有多少商品；统计各种状态（Status）的订单数

**基础语法**：

```js
GET /products/_search
{
  "size": 0,
  "aggs": {
    "group_by_category": {    // 1. 给聚合起个名
      "terms": {              // 2. 选择策略：terms
        "field": "category",  // 3. 指定字段 (必须是 keyword)
        "size": 10            // 4. 只返回数量最多的 Top 10
      }
    }
  }
}
```



**⚠️ 经典报错：Fielddata is disabled**

- **现象**：当你对 `title` (Text 类型) 进行聚合时，ES 报错
- **原因**：Text 字段在内存中是倒排索引，不适合做聚合（聚合需要正排索引）
- **解决**：必须使用 **`title.keyword`** 子字段。如果非要聚合 Text，需开启 `fielddata: true`（极度消耗内存，**生产环境严禁开启**）



**🔍 进阶理解：数据准确性**

Terms 聚合在分布式系统中是 **“有损”** 的

- **问题**：如果数据分散在 3 个分片，你查 Top 5。ES 会让每个分片各自交出 Top 5，然后汇总
- **结果**：某些在各分片排名第 6 的数据，可能汇总后其实能进全局 Top 5，但被漏掉了
- **优化**：增加 `shard_size` 参数（让分片多交点数据给协调节点），或者提高 `size` 值



#### 2. Histogram Aggregation (数值直方图)

如果字段是连续的数值（如价格、体重），用 `terms` 聚合会得到成千上万个桶，不仅性能差，而且没意义。 我们需要的是 **“区间”**

- **场景**：价格分布图。每 1000 元一个区间（0-1000, 1000-2000...）

**语法示例**：

```js
GET /products/_search
{
  "size": 0,
  "aggs": {
    "price_ranges": {
      "histogram": {
        "field": "price",
        "interval": 1000,      // 步长：每 1000 一个桶
        "min_doc_count": 1     // 优化：如果某个区间没数据，就不显示这个桶
      }
    }
  }
}
```



#### 3. Date Histogram (时间直方图)

这是做 **“趋势图”** 的神器

- **场景**：统计过去一年每月的销量趋势
- **核心参数**：
  - `calendar_interval`: 也就是步长 (month, day, hour)
  - `format`: 返回的时间格式

**语法示例**：

```js
GET /products/_search
{
  "size": 0,
  "aggs": {
    "sales_trend": {
      "date_histogram": {
        "field": "created_at",
        "calendar_interval": "month", // 按月统计
        "format": "yyyy-MM",          // Key 显示为 "2023-01"
        "time_zone": "+08:00"         // 🚨 关键：修正时区！否则按 UTC 0点切分
      }
    }
  }
}
```

> **💡 时区避坑指南** 
>
> - ES 内部存的是 UTC 时间
>   - 如果你是中国用户，不加 `time_zone: "+08:00"`，会导致每天的 **00:00 - 08:00** 的数据被算到 **前一天** 去！做日报表时这个坑非常大



#### 4. 总结

| 聚合类型           | 对应场景                 | 关键参数            | 避坑点                        |
| ------------------ | ------------------------ | ------------------- | ----------------------------- |
| **Terms**          | 离散值分组 (品牌/状态)   | `size`, `order`     | 必须用 Keyword；结果是近似值  |
| **Histogram**      | 连续数值分布 (价格/销量) | `interval`          | 设置 `min_doc_count` 过滤空桶 |
| **Date Histogram** | 时间趋势 (年/月/日)      | `calendar_interval` | 必须设置 `time_zone` 修正时区 |



### 5.3 嵌套聚合：多维分析与排序

ES 聚合的真正威力在于其 **可嵌套性**

- 你可以在一个“分桶”内部，再进行“分桶”或者“指标计算”。这种结构在语法上表现为 `aggs` 套 `aggs`，逻辑上类似于 SQL 的多层 `GROUP BY` 或窗口函数

#### 1. 核心思维：桶内计算

这是最常见的嵌套模式：**先分类，再统计**

- **场景**：我想知道“手机”、“电脑”、“电视”这几个分类下，**最贵** 的商品分别是多少钱？**平均价** 是多少？

**DSL 代码详解**：

```js
GET /products/_search
{
  "size": 0,
  "aggs": {
    // Level 1: 父聚合（先按分类切分）
    "group_by_category": {
      "terms": {
        "field": "category",
        "size": 10
      },
      
      // Level 2: 子聚合（在每个分类桶内部搞事情）
      "aggs": {
        // 子聚合 A: 计算当前桶内的最大值
        "max_price_in_bucket": {
          "max": {
            "field": "price"
          }
        },
        // 子聚合 B: 计算当前桶内的平均值
        "avg_price_in_bucket": {
          "avg": {
            "field": "price"
          }
        }
      }
    }
  }
}
```

**返回结果解析**： ES 会在每个 Bucket 中增加子聚合的计算结果

```js
"buckets": [
  {
    "key": "手机",
    "doc_count": 100,
    "max_price_in_bucket": { "value": 6999 }, // 手机桶内的最高价
    "avg_price_in_bucket": { "value": 3500 }  // 手机桶内的平均价
  },
  {
    "key": "电脑",
    "doc_count": 50,
    "max_price_in_bucket": { "value": 12999 },
    "avg_price_in_bucket": { "value": 8000 }
  }
]
```



#### 2. 进阶痛点：基于子聚合排序

**默认行为**： `terms` 聚合默认按 `doc_count` (文档数量) 降序排列。也就是说，**卖得最多** 的分类排在前面

**业务需求**： 我是个高端买手，我希望 **“平均价格”最贵** 的分类排在前面

**解决方案**： 在父聚合 (`terms`) 中使用 `order` 参数，引用子聚合的名称

**DSL 代码**：

```js
GET /products/_search
{
  "size": 0,
  "aggs": {
    "group_by_category": {
      "terms": {
        "field": "category",
        
        // 🚀 核心技巧：自定义排序
        "order": {
          "avg_price_calc": "desc" // 指向下方子聚合的名字 "avg_price_calc"
        }
      },
      
      "aggs": {
        // 子聚合：必须存在，才能被引用
        "avg_price_calc": {
          "avg": { "field": "price" }
        }
      }
    }
  }
}
```



#### 3. 深度嵌套风险

虽然 ES 支持无限嵌套（按品牌 $\to$ 按产地 $\to$ 按颜色 $\to$ 算价格），但在生产环境中，**严禁超过 3 层嵌套**

- **组合爆炸**：
  - 第一层 10 个桶
  - 第二层每个桶里再分 10 个 $\to$ 100 个计算单元
  - 第三层每个里再分 10 个 $\to$ 1000 个计算单元
- **后果**：内存消耗呈指数级增长，极易触发 **Circuit Breaker (熔断)** 甚至导致节点 OOM (Out Of Memory) 宕机

> **架构建议**： 
>
> - 如果业务确实需要极深维度的交叉分析（例如 5 层以上维度的自由组合），Elasticsearch 可能不是最佳选择
>   - 建议将数据清洗后导入 **ClickHouse** 或 **Doris** 等专用 OLAP 引擎进行处理



## 06. Java 客户端选型与环境集成

### 6.1 客户端的“乱世演义”：我们该选谁？

在开始写代码前，必须先选对“武器”。ES 的 Java 客户端经历了三次大的变革，选错版本会导致代码完全跑不起来

#### 1. 历史版本回顾 (避坑必读)

| 客户端名称              | 状态         | 通信协议    | 评价                                                         |
| ----------------------- | ------------ | ----------- | ------------------------------------------------------------ |
| **TransportClient**     | 💀 **已移除** | TCP (9300)  | **上古时代的产物**。<br />直接连接 ES 集群节点，耦合度极高，ES 服务端升级它就得跟着升级<br />ES 7.0 废弃，ES 8.0 彻底移除。**千万别学了** |
| **RestHighLevelClient** | ⚠️ **已废弃** | HTTP (9200) | **曾经的王者**。基于 HTTP 协议，封装比较完善。<br />但在 ES 7.15.0 宣布废弃，ES 8.x 官方不再建议新项目使用<br />**市面上 90% 的老教程（如黑马程序员）讲的都是这个，请注意甄别** |
| **Java API Client**     | ✅ **新标准** | HTTP (9200) | **未来的主流**。ES 8.0 推出的全新官方客户端<br />采用更现代的 **Builder 模式** 和 **Lambda 表达式** 风格，与 HTTP 协议完全解耦<br />**我们要学的就是这个** |



#### 2. Spring Data Elasticsearch：最强辅助

很多同学会纠结：“我是用官方的 `Java API Client`，还是用 Spring 封装的 `Spring Data`？”

**答案是：都要用**

Spring Boot 3.x (`spring-boot-starter-data-elasticsearch`) 的底层已经默认切换到了 **Java API Client**

- 它为我们提供了一套 **“混合双打”** 的架构模式：

  - **Repository 接口** (高层封装)：

    - **作用**：像写 MyBatis-Plus 或 JPA 一样，通过继承 `ElasticsearchRepository` 接口，零 SQL 实现基础 CRUD
    - **场景**：根据 ID 查询、保存对象、简单的单条件搜索
    - **优点**：代码极简，开发效率高

    

  - **ElasticsearchClient** (原生对象)：
    - **作用**：Spring 会自动帮你配置并注入这个原生客户端 Bean
    - **场景**：复杂的 Bool 嵌套查询、聚合分析 (Aggregations)、高亮显示、批量操作 (Bulk)
    - **优点**：灵活强大，支持 ES 所有高级特性

> **架构结论**： 在实际项目中，我们将 **同时注入** `ProductRepository` (处理简单业务) 和 `ElasticsearchClient` (处理复杂搜索)



#### 3. 版本兼容性地狱

这是 Spring Boot 整合 ES 最容易翻车的地方。**Spring Boot 的版本必须与 Elasticsearch 服务端版本严格匹配**

- **原则**：Spring Boot 的发布时间通常滞后于 ES
- **现状 (Spring Boot 3.2.x)**：默认适配 Elasticsearch **8.10+**
- **风险**：如果你服务器上装的是 ES 7.x，而项目用了 Spring Boot 3，启动时会直接报错（类找不到或方法签名不匹配）

**解决方案**： 在 `pom.xml` 中显式锁定 ES 版本，强制让 Spring 使用与你服务器一致的版本

```xml
<properties>
    <!-- 强制覆盖 Spring Boot 默认的 ES 版本，确保与服务端一致 -->
    <elasticsearch.version>8.12.2</elasticsearch.version>
</properties>
```



### 6.2 Spring Boot 3 项目集成实战

环境准备：

- **JDK**: 17+ (Spring Boot 3 硬性要求)
- **Spring Boot**: 3.2.x
- **Elasticsearch**: 8.12.2 (Docker 已运行)



#### 1. 依赖管理 (pom.xml)

这是项目的地基。我们需要引入核心 Starter，并强制锁定 ES 版本以避免兼容性问题

```xml
<dependencies>
    <!-- 1. Web 模块 (方便写 Controller 测试) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- 2. Spring Data Elasticsearch (核心) -->
    <!-- 包含: Repository 支持 + 新版 Java API Client -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-elasticsearch</artifactId>
    </dependency>
    
    <!-- 3. Jakarta JSON (兜底防报错) -->
    <!-- 新版 ES Client 强依赖 Jakarta EE，显式引入可防止部分环境缺少包 -->
    <dependency>
        <groupId>jakarta.json</groupId>
        <artifactId>jakarta.json-api</artifactId>
        <version>2.1.3</version>
    </dependency>

    <!-- 4. Lombok & Test -->
    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
        <optional>true</optional>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>

<!-- 🚨 核心配置：锁定 ES 版本 -->
<properties>
    <elasticsearch.version>8.12.2</elasticsearch.version>
</properties>
```



#### 2. 配置文件 (application.yml)

在实际生产环境中，仅配置基础 URL 是远远不够的。为了保证系统的稳定性与安全性，我们需要配置 **超时时间**、**账号密码** 以及 **调试日志**

```yaml
spring:
  elasticsearch:
    # 1. 连接地址 (集群模式用逗号分隔)
    # 格式: protocol://host:port
    uris: http://localhost:9200
    
    # 2. 账号密码 (生产环境必填)
    # 如果你的 Docker 开启了 xpack，这里必须填
    # username: elastic
    # password: your_strong_password
    
    # 3. 超时设置 (生产环境必调)
    # 避免网络波动导致线程卡死
    socket-timeout: 30s      # 读取数据超时
    connection-timeout: 5s   # 建立连接超时

# 4. 开发调试黑科技
logging:
  level:
    # 开启 Tracer 日志，能在控制台看到 Spring 生成的原始 JSON DSL
    # 相当于 MySQL 的 show-sql，排查问题神器！
    org.springframework.data.elasticsearch.client.WIRE: trace
```



#### 3. 环境连通性测试 (Hello World)

不要急着写业务代码，先写一个单元测试，确保 Java 能跟 ES 握手成功

**测试目标**：注入原生客户端 `ElasticsearchClient`，查询集群版本信息

```java
package com.example.demo;

import co.elastic.clients.elasticsearch.ElasticsearchClient;
import co.elastic.clients.transport.Version;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import java.io.IOException;

@SpringBootTest
class ConnectionTest {

    // 注入新版原生客户端 (Spring Boot 自动配置好的 Bean)
    @Autowired
    private ElasticsearchClient esClient;

    @Test
    void testConnection() throws IOException {
        // 发送请求: GET /
        var response = esClient.info();
        
        System.out.println("----------------------------------");
        System.out.println("✅ 连接成功！");
        System.out.println("ES 版本: " + response.version().number());
        System.out.println("Lucene 版本: " + response.version().luceneVersion());
        System.out.println("----------------------------------");
    }
}
```

**预期输出**：

```
----------------------------------
✅ 连接成功！
ES 版本: 8.12.2
Lucene 版本: 9.9.2
----------------------------------
```



#### 4. 常见报错排查

如果在这一步报错，通常是以下原因：

1. **Connection Refused**: ES 没启动，或者 Docker 端口映射没做 (9200)
2. **Unauthorized**: 你的 ES 开启了 xpack (默认行为)，但你在 YAML 里没填账号密码，或者填错了
3. **PKIX path building failed**: 你试图用 `http` 协议连接开启了 `https` 的 ES，或者证书不信任
   - *解决*：开发环境建议在 Docker 设置中关闭 SSL (`xpack.security.http.ssl.enabled=false`)
   - *解决*：或者将 YAML 中的 `uris` 改为 `https://...` 并配置 TrustStore







## 07. Spring Data Elasticsearch

### 7.1 实体映射：把 Java 对象变成 ES 文档

在 Spring Data 中，我们需要定义一个 POJO 类来描述索引的结构（Schema）。ES 会读取这些注解，在启动时（默认情况下）自动创建索引和 Mapping

#### 1. 核心注解清单 (API)

这些注解都位于 `org.springframework.data.elasticsearch.annotations` 包下

| 注解              | 作用                                  | 关键属性                                                     |
| ----------------- | ------------------------------------- | ------------------------------------------------------------ |
| **`@Document`**   | **类级别**。标记这是一个 ES 实体类    | `indexName`: 对应索引名。`createIndex`: 是否自动创建索引（生产环境建议 false） |
| **`@Id`**         | **字段级别**。标记主键                | 无。对应 ES 中的 `_id` 元数据                                |
| **`@Field`**      | **字段级别**。定义字段的 Mapping 属性 | `type`: 字段类型 (Text, Keyword, Date...)。`analyzer`: 指定分词器。`name`: 指定 ES 中的字段名（如果和 Java 属性名不同） |
| **`@DateFormat`** | **配合 @Field**。定义日期格式         | 解决 Java `LocalDateTime` 与 ES 时间戳的转换问题             |



#### 2. 代码实战：定义 Product 实体

请在项目中创建一个 `model` 或 `entity` 包，并新建 `Product.java`

```java
package com.example.demo.entity;

import lombok.Data;
import org.springframework.data.annotation.Id;
import org.springframework.data.elasticsearch.annotations.DateFormat;
import org.springframework.data.elasticsearch.annotations.Document;
import org.springframework.data.elasticsearch.annotations.Field;
import org.springframework.data.elasticsearch.annotations.FieldType;

import java.time.LocalDateTime;

@Data
// 1. 标记为文档，指定索引名为 "products"
@Document(indexName = "products")
public class Product {

    // 2. 映射 _id。建议使用 String 类型，因为 ES 的 ID 本质是字符串。
    @Id
    private String id;

    // 3. 定义 Text 类型，并指定分词器
    // 写入时用 ik_max_word (细粒度)，搜索时用 ik_smart (粗粒度)
    @Field(type = FieldType.Text, analyzer = "ik_max_word", searchAnalyzer = "ik_smart")
    private String title;

    // 4. Keyword 类型：不分词，用于精确匹配、聚合、排序
    @Field(type = FieldType.Keyword)
    private String category;

    // 5. 数值类型
    @Field(type = FieldType.Double)
    private Double price;

    // 6. 日期类型 (坑点高发区 🚨)
    // 必须指定 format，否则 Java 的 LocalDateTime 序列化到 ES 时会报错
    @Field(type = FieldType.Date, format = DateFormat.date_hour_minute_second_millis)
    private LocalDateTime createdAt;

    // 7. 布尔类型
    @Field(type = FieldType.Boolean)
    private Boolean isActive;
}
```



#### 3. 避坑指南

1. **日期类型的坑**：
   - ES 底层默认存储的是 UTC 时间戳（Long）
   - Java 的 `LocalDateTime` 没有时区概念
   - **建议**：在 `@Field` 中显式指定 `format`，或者干脆在 Java 侧用 `Long` 类型存储时间戳，避免繁琐的时间格式转换问题
2. **自动创建索引 (createIndex)**：
   - `@Document(createIndex = true)` 是默认值。Spring 启动时会检查索引是否存在，不存在则创建
   - **生产环境建议**：设置为 `false`。索引的创建和 Mapping 的维护应该通过运维脚本或专门的迁移工具（Review 机制）来管理，而不是由应用程序启动时静默触发，防止代码修改意外覆盖了线上配置
3. **主键生成策略**：
   - 如果在保存时 `id` 字段为 `null`，ES 会自动生成一个随机 UUID
   - 如果 `id` 有值，则是“新增或覆盖（Upsert）”



### 7.2 Repository 接口开发：零 SQL 实现 CRUD

#### 1. 定义接口 (Interface Definition)

在 `repository` 包下创建 `ProductRepository` 接口

- **关键点**：继承 `ElasticsearchRepository<T, ID>`
  - `T`: 实体类类型 (`Product`)
  - `ID`: 主键类型 (`String`)

```java
package com.example.demo.repository;

import com.example.demo.entity.Product;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.elasticsearch.annotations.Query;
import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;
import java.util.List;

public interface ProductRepository extends ElasticsearchRepository<Product, String> {

    // ---------------------------------------------------------
    // 第一层：继承父接口获得的方法 (无需声明，直接用)
    // ---------------------------------------------------------
    // save(entity), saveAll(entities) -> 增/改
    // findById(id), findAll()         -> 查
    // deleteById(id), delete(entity)  -> 删
    
    // ---------------------------------------------------------
    // 第二层：方法名衍生查询 (Derived Queries)
    // ---------------------------------------------------------
    // Spring 会解析方法名，自动生成 DSL。
    // 类似于: SELECT * FROM product WHERE category = ?
    List<Product> findByCategory(String category);

    // 类似于: SELECT * FROM product WHERE price BETWEEN ? AND ?
    List<Product> findByPriceBetween(Double min, Double max);

    // 类似于: SELECT * FROM product WHERE title LIKE ?
    // 注意：在 ES 中这通常对应 "match" 查询
    List<Product> findByTitleMatches(String title);

    // 带分页的查询
    // 调用方式: findByTitleMatches("华为", PageRequest.of(0, 10))
    Page<Product> findByTitleMatches(String title, Pageable pageable);

    // ---------------------------------------------------------
    // 第三层：@Query 自定义 DSL (终极武器)
    // ---------------------------------------------------------
    // 当方法名太长写不下，或者逻辑太复杂时，直接写 JSON DSL。
    // ?0 代表第一个参数，?1 代表第二个参数
    @Query("{\"match\": {\"title\": {\"query\": \"?0\"}}}")
    List<Product> findByNameCustom(String title);
}
```



#### 2. 单元测试实战 (Unit Test)

我们直接在测试类中注入这个接口，看看它是怎么工作的

```java
@SpringBootTest
class ProductRepositoryTest {

    @Autowired
    private ProductRepository productRepository;

    @Test
    void testCrud() {
        // 1. 新增 (Create)
        Product p = new Product();
        p.setId("1001");
        p.setTitle("华为 Mate 60 Pro");
        p.setCategory("手机");
        p.setPrice(6999.0);
        p.setIsActive(true);
        
        productRepository.save(p); // 自动生成 index 请求
        System.out.println("保存成功");

        // 2. 查询 (Read)
        // Optional<T> 是 Java 8 标准
        productRepository.findById("1001").ifPresent(product -> {
            System.out.println("查到商品: " + product.getTitle());
        });

        // 3. 按价格区间查询 (Custom Method)
        List<Product> cheapPhones = productRepository.findByPriceBetween(1000.0, 5000.0);
        System.out.println("5000元以下的手机有: " + cheapPhones.size() + " 个");

        // 4. 删除 (Delete)
        productRepository.deleteById("1001");
    }
}
```



#### 3. 避坑指南：Repository 的局限性

虽然 Repository 很爽，但它有明显的**天花板**：

1. **复杂聚合不支持**：如果你要做类似“按月统计每个品牌的平均销量”这种报表分析，Repository 的方法名无法表达（或者写出来极其变态）
2. **动态查询困难**：如果你的搜索条件是动态的（比如用户有时候选价格，有时候选品牌，有时候两个都选），用 Repository 需要写大量的 `if-else` 来调用不同的方法，非常丑陋
3. **高亮显示 (Highlight)**：虽然 Spring Data 只有有限的支持，但处理起来比较麻烦，不如原生 Client 灵活

**结论**：

- 简单的 CRUD、根据 ID 查、根据单个字段查 -> **用 Repository**
- 复杂搜索、动态过滤、聚合分析、高亮 -> **需要用 ElasticsearchClient（下一节的内容）**



## 08. Elasticsearch Java API Client 实战

### 8.1 为什么我们需要原生 Client？

Spring Data Repository 虽然方便，但在面对以下场景时会显得力不从心：

1. **复杂嵌套查询**：比如 4 层嵌套的 Bool 查询
2. **聚合分析 (Aggregations)**：Repository 方法名无法表达复杂的聚合逻辑
3. **高亮显示 (Highlighting)**：虽然 Repository 支持，但灵活性较差
4. **精确控制**：需要手动控制 `track_total_hits`、`min_score` 或 `search_after` 参数

Elasticsearch 8.x 推出的 **Java API Client** 采用了全新的 **Builder + Lambda** 设计模式，代码结构与 JSON DSL 高度对应，是解决复杂问题的终极武器



### 8.2 基础查询实战

#### 1. 注入客户端

在 Service 或 Test 类中注入 `ElasticsearchClient`

```java
@Autowired
private ElasticsearchClient esClient;
```



#### 2. 构建查询 (Fluent API)

我们要实现这个 DSL：

```js
GET /products/_search
{
  "query": {
    "match": { "title": "华为" }
  }
}
```



**Java 代码实现**：

```js
@Test
void testSimpleSearch() throws IOException {
    // 1. 发起搜索请求
    SearchResponse<Product> response = esClient.search(s -> s
            .index("products") // 指定索引
            .query(q -> q      // 构建查询
                .match(m -> m  // match 查询
                    .field("title")
                    .query("华为")
                )
            ),
        Product.class // 结果映射的目标类
    );

    // 2. 解析结果
    long total = response.hits().total().value();
    System.out.println("共搜索到 " + total + " 条数据");

    for (Hit<Product> hit : response.hits().hits()) {
        Product p = hit.source();
        System.out.println("商品名: " + p.getTitle() + ", 分数: " + hit.score());
    }
}
```



### 8.3 复杂 Bool 查询实战 (核心)

还记得我们在 4.4 节写的那个复杂 DSL 吗？

- **Must**: 标题包含 "华为"
- **Filter**: 价格 > 2000
- **Filter**: 有库存
- **Must Not**: 标签包含 "second_hand"
- **Should**: 标题包含 "5G"

**Java 代码实现**：

```js
@Test
void testBoolQuery() throws IOException {
    SearchResponse<Product> response = esClient.search(s -> s
        .index("products")
        .query(q -> q
            .bool(b -> b
                // 1. Must
                .must(m -> m
                    .match(t -> t
                        .field("title")
                        .query("华为")
                    )
                )
                // 2. Filter (多个条件用 add)
                .filter(f -> f
                    .range(r -> r
                        .field("price")
                        .gt(JsonData.of(2000)) // 注意: 数值需包装
                    )
                )
                .filter(f -> f
                    .term(t -> t
                        .field("isActive")
                        .value(true)
                    )
                )
                // 3. Must Not
                .mustNot(mn -> mn
                    .term(t -> t
                        .field("tags")
                        .value("second_hand")
                    )
                )
                // 4. Should
                .should(sh -> sh
                    .match(m -> m
                        .field("title")
                        .query("5G")
                    )
                )
            )
        ),
        Product.class
    );
    
    // ... 解析结果同上
}
```



### 8.4 聚合分析实战 (Aggregations)

**需求**：统计每个分类下的商品数量，并按数量降序排列

```java
@Test
void testAggregation() throws IOException {
    String aggName = "group_by_category";

    SearchResponse<Void> response = esClient.search(s -> s
        .index("products")
        .size(0) // 只需要聚合结果，不需要文档列表
        .aggregations(aggName, a -> a
            .terms(t -> t
                .field("category")
                .size(10)
            )
        ),
        Void.class // 泛型填 Void 因为不解析 hits
    );

    // 解析聚合结果
    // 1. 获取聚合体 (注意类型强转)
    Aggregate aggregate = response.aggregations().get(aggName);
    
    // 2. 只有 Terms 类型的聚合才能转成 StringTermsAggregate
    StringTermsAggregate termsAgg = aggregate.sterms();

    // 3. 遍历桶
    for (StringTermsBucket bucket : termsAgg.buckets().array()) {
        String categoryName = bucket.key().stringValue();
        long docCount = bucket.docCount();
        System.out.println("分类: " + categoryName + ", 数量: " + docCount);
    }
}
```



### 8.5 避坑指南

1. **Lambda 层级过深**：
   - Java Client 的 Lambda 写法虽然还原了 JSON 结构，但层级一旦深了（超过 5 层），代码可读性会急剧下降
   - **建议**：将复杂的 Query 构建逻辑抽取成独立的方法（例如 `buildBoolQuery()`），保持主流程清晰
2. **JsonData 包装**：
   - 在构建 `range` 查询或某些参数时，数值和对象需要用 `JsonData.of(value)` 进行包装，直接传 `int` 有时会报错
3. **结果解析类型安全**：
   - 聚合结果解析时，必须非常清楚你的聚合类型是 Terms、Histogram 还是 Avg。如果类型强转错误（比如把 `sterms` 转成了 `lterms`），会抛出异常



## 09. 生产环境常见问题与数据同步 (1/N)

### 9.1 MySQL 与 ES 的数据同步方案

Elasticsearch 是一个“从数据源”，它的数据通常是从 MySQL（主数据源）流转过来的。根据业务对**实时性**和**一致性**要求的不同，主要有三种同步策略

#### 1. 方案一：同步双写

这是最直观、最简单的方案。在代码层面，更新数据库的同时，顺便更新 ES

- **代码逻辑**：

  ```java
  @Transactional
  public void updateProduct(Product product) {
      // 1. 写 MySQL
      productMapper.updateById(product);
  
      // 2. 写 ES
      // ⚠️ 风险点：如果 MySQL 成功，ES 失败（比如网络超时），数据就不一致了！
      esClient.index(product); 
  }
  ```

- **优点**：

  - 简单粗暴，实时性极高（基本是毫秒级）

- **缺点 (巨坑)**：

  - **硬耦合**：业务代码和 ES 搜索代码绑死在一起
  - **数据不一致**：无法保证 MySQL 和 ES 的分布式事务。如果 ES 写失败，虽然可以回滚 MySQL，但如果 MySQL 提交成功后 ES 挂了，数据就丢了
  - **性能损耗**：用户请求的响应时间 = MySQL 耗时 + ES 耗时



#### 2. 方案二：异步 MQ 通知 (Asynchronous MQ)

为了解决耦合和性能问题，我们可以引入消息队列（RabbitMQ / RocketMQ / Kafka）

- **流程**：
  1. 业务系统只写 MySQL
  2. 业务系统发送一条“商品变更消息”到 MQ（例如：`product_id: 1001, action: UPDATE`）
  3. 单独起一个“搜索服务”消费 MQ，拿到 ID 后去查 MySQL，然后写入 ES
- **优点**：
  - **解耦**：核心业务不再依赖 ES 的稳定性
  - **削峰填谷**：在流量洪峰时，MQ 可以缓冲写入压力，保护 ES
- **缺点**：
  - **延迟**：数据可能有秒级延迟
  - **代码侵入**：还是需要在业务代码里发 MQ 消息。如果忘了发，数据就不同步了



#### 3. 方案三：监听 Binlog (CDC - Change Data Capture) —— 👑 推荐方案

这是目前大厂最主流的 **无侵入** 同步方案。它把 ES 当作 MySQL 的一个“从库”

- **工具选型**：阿里巴巴 **Canal** (最成熟)、Debezium
- **流程**：
  1. MySQL 开启 Binlog（二进制日志）
  2. 部署 Canal Server，它伪装成 MySQL 的 Slave 节点，向 MySQL Master 发送 dump 协议
  3. MySQL 收到请求，推送 Binlog 给 Canal
  4. Canal 解析 Binlog（变成 JSON 格式：`{before:..., after:..., type: UPDATE}`），发送到 MQ
  5. 消费者服务消费 MQ，写入 ES
- **优点**：
  - **完全解耦**：业务代码一行都不用改，随便你怎么写 SQL，只要数据变了，ES 就会自动变
  - **零丢失**：Canal 支持断点续传
- **缺点**：
  - 架构复杂，维护成本高（需要维护 Canal、MQ、Consumer 组件）

#### 💡 选型建议

| 场景                          | 推荐方案              | 理由                                                     |
| ----------------------------- | --------------------- | -------------------------------------------------------- |
| **初创公司 / 小项目**         | **方案一 (同步双写)** | 还没遇到高并发，先活下来最重要。代码简单，出了问题好排查 |
| **中型项目 / 对实时性要求高** | **方案二 (MQ)**       | 业务代码改动可控，利用 MQ 保证最终一致性                 |
| **大型架构 / 遗留系统改造**   | **方案三 (Canal)**    | 业务代码不能动，数据量大，必须完全解耦                   |



### 9.2 生产环境避坑：脑裂

这是一个导致集群数据永久丢失的恐怖问题

- **现象**： 一个集群中突然出现了**两个 Master 节点**

  - 节点 A 认为自己是老大，节点 B 也认为自己是老大
  - 结果：索引数据一部分写入了 A 管理的分片，一部分写入了 B 管理的分片。数据四分五裂，无法合并

- **原因**： 网络波动导致节点间通信中断。A 以为 B 挂了，自己当了主；B 以为 A 挂了，自己也当了主

- **解决方案 (Elasticsearch 7.x 以前)**： 必须配置 `discovery.zen.minimum_master_nodes = (N/2) + 1`

  - 比如 3 个节点，设为 2。只有得到 2 票才能当 Master

- **现状 (Elasticsearch 7.x+ / 8.x)**： 

  - 🎉 **好消息**：ES 7.0 以后引入了全新的集群协调子系统，**自动处理了脑裂问题**

    只要你配置好 `cluster.initial_master_nodes`，ES 会自动通过 Raft 算法选举，不再需要人工计算这个公式

    但**网络分区**依然是集群最大的杀手，保证内网的稳定性至关重要



## 10. 进阶实战：性能优化与零停机运维

### 10.1 写入性能优化

ES 默认的配置是为了“搜索实时性”优先（数据写入 1 秒后就能搜到）。但在海量数据导入场景下，这会严重拖慢写入速度

如果你的 ES 写入遇到瓶颈（CPU 飙升、拒绝连接），请尝试以下三大优化手段：



#### 1. 调整刷新间隔 (Refresh Interval) —— 效果最立竿见影

- **原理**： ES 默认 `refresh_interval: "1s"`。这意味着每秒钟 ES 都要把内存里的数据写到文件系统缓存中，并生成一个新的 Segment 文件。这会消耗大量的 CPU 和 I/O
- **优化策略**：
  - **日常运行**：如果业务允许 30 秒延迟，可以设为 `"30s"`
  - **批量导入时**：直接设为 `"-1"`（关闭自动刷新）。等导完几亿条数据后，再改回来

```js
PUT /products/_settings
{
  "index": {
    "refresh_interval": "30s" 
  }
}
```



#### 2. 也是老生常谈：Bulk 批处理

- **原理**：减少网络开销和线程切换
- **建议**：
  - 单次 Bulk 大小建议在 **5MB - 15MB** 之间
  - Spring Data Elasticsearch 默认的 `saveAll()` 底层就是 Bulk



#### 3. 异步 Translog (Translog Durability)

- **原理**： 

  - 为了保证数据不丢，ES 默认每写一条数据，都会把操作记录 fsync 到磁盘的 Translog 文件（`request` 模式）

    这和 MySQL 的“双一”策略类似，非常安全但非常慢

- **优化策略**： 如果允许在极端宕机情况下丢失最近 5 秒的数据（例如日志场景），可以改为 **异步刷盘 (async)**

```js
PUT /products/_settings
{
  "index.translog.durability": "async",
  "index.translog.sync_interval": "5s"
}
```



### 10.2 零停机索引重构：别名 (Alias) 的妙用

**痛点**： 

- ES 的 Mapping 是 **不可变** 的。如果你把 `price` 字段定义成了 `integer`，后来发现不够用，想改成 `double`，或者想修改分词器，必须**重建索引**

  但在生产环境，你不能把服务停了来做这件事

**解决方案：永远使用别名 (Always use Alias)**

#### 1. 什么是别名？

别名就像是数据库的“视图”或者域名的 CNAME

- **物理索引**：`products_v1`（真实存储数据的地方）
- **逻辑别名**：`products`（应用层代码使用的名字）

**应用层代码**：

```java
@Document(indexName = "products") // 永远只指向别名
public class Product { ... }
```



#### 2. 零停机迁移实战步骤 (The Blue-Green Deployment)

假设当前应用正在使用 `products_v1`

**Step 1: 创建新索引 (Create V2)** 创建一个新的索引 `products_v2`，修改 Mapping（比如把 price 改成 double）

```js
PUT /products_v2
{
  "mappings": { ...新结构... }
}
```

**Step 2: 数据迁移 (Reindex)** 使用 `_reindex` API 把 V1 的数据抄到 V2。这个过程是后台进行的，不影响 V1 的正常读写（只要不是并发写入极高）。

```js
POST /_reindex
{
  "source": { "index": "products_v1" },
  "dest":   { "index": "products_v2" }
}
```

**Step 3: 原子切换 (Atomic Switch) —— 关键** 这是最骚的一步。我们需要在一个原子操作中，把别名 `products` 从 V1 身上撕下来，贴到 V2 身上。 **用户完全无感知。**

```js
POST /_aliases
{
  "actions": [
    { "remove": { "index": "products_v1", "alias": "products" } },
    { "add":    { "index": "products_v2", "alias": "products" } }
  ]
}
```

**Step 4: 验证与清理** 现在应用查 `products`，实际上查的是 `products_v2`。确认无误后，可以删除 `products_v1` 回收空间。

```js
DELETE /products_v1
```